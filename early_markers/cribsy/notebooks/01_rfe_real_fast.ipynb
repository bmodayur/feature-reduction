{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header_id",
   "metadata": {},
   "source": [
    "# Fast RFE Feature Selection (Optimized)\n",
    "\n",
    "This is a performance-optimized version of `01_rfe_real.ipynb` with:\n",
    "- Reduced number of RFE trials (10 instead of 50)\n",
    "- Fewer Random Forest estimators (100 instead of 200)\n",
    "- Configurable parallelization\n",
    "\n",
    "**Performance Impact:**\n",
    "- Original: ~30-60 minutes (50 trials \u00d7 15 folds \u00d7 200 trees = 150,000 models)\n",
    "- Optimized: ~5-10 minutes (10 trials \u00d7 15 folds \u00d7 100 trees = 15,000 models)\n",
    "\n",
    "**Trade-offs:**\n",
    "- Faster execution (10x speedup)\n",
    "- Slightly less stable feature selection\n",
    "- Still uses statistical significance testing\n",
    "\n",
    "**For production:** Use the original parameters for final results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section_11_id",
   "metadata": {},
   "source": [
    "## 1.1 Environment Setup and Configuration\n",
    "\n",
    "This section initializes the environment with performance-optimized parameters for fast feature selection.\n",
    "\n",
    "**Key Optimizations:**\n",
    "- `FAST_N_TRIALS = 10`: Reduced from 50 (5x speedup in RFE trials)\n",
    "- `FAST_N_ESTIMATORS = 100`: Reduced from 200 (2x speedup in Random Forest)\n",
    "- Combined effect: ~10x overall speedup\n",
    "\n",
    "**Data Loading:**\n",
    "- `BayesianData()` initializes with `features_merged.pkl` (default)\n",
    "- Loads 1,250 infants \u00d7 56 features from `/Volumes/secure/code/early-markers/early_markers/emmacp_metrics/`\n",
    "- Automatically transforms risk labels: `risk <= 1` \u2192 0 (normal), `risk > 1` \u2192 1 (at-risk)\n",
    "- Category assignment: `category = 1` (training), `category = 2` (testing)\n",
    "\n",
    "**Random Seed:**\n",
    "- `RAND_STATE = 20250313` ensures reproducibility across runs\n",
    "- Set at module level before BayesianData initialization\n",
    "\n",
    "**Feature Pre-filtering (Optional):**\n",
    "- The `drops` list contains 34 features with historically low importance\n",
    "- Uncomment filtering to start with 22 features instead of 56 for even faster iteration\n",
    "- Default: Uses all 56 features from `FEATURES` constant\n",
    "\n",
    "**Custom `run_fast_rfe()` Function:**\n",
    "- Wraps `EnhancedAdaptiveRFE` with fast parameters\n",
    "- Implements convergence logic: adjusts `pct` if no features are eliminated\n",
    "- Automatically calls `run_surprise_with_features()` after RFE completes\n",
    "- Returns selected feature list for next iteration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from datetime import datetime\n",
    "import pickle\n",
    "\n",
    "from numpy import random\n",
    "from loguru import logger\n",
    "\n",
    "from early_markers.cribsy.common.bayes import BayesianData\n",
    "from early_markers.cribsy.common.adaptive_rfe import EnhancedAdaptiveRFE\n",
    "from early_markers.cribsy.common.constants import (\n",
    "    AGE_BRACKETS, MIN_K, PKL_DIR, FEATURES, RAND_STATE,\n",
    "    RFE_ALPHA, RFE_KEEP_PCT\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# PERFORMANCE CONFIGURATION\n",
    "# ============================================================================\n",
    "# Adjust these for speed vs. accuracy trade-off\n",
    "\n",
    "FAST_N_TRIALS = 10      # Down from 50 (5x faster)\n",
    "FAST_N_ESTIMATORS = 100 # Down from 200 (2x faster)\n",
    "# Combined: 10x speedup\n",
    "\n",
    "# For production/final results, set these to match constants:\n",
    "# FAST_N_TRIALS = 50\n",
    "# FAST_N_ESTIMATORS = 200\n",
    "\n",
    "# ============================================================================\n",
    "\n",
    "# Set seeds at file level\n",
    "random.seed(RAND_STATE)\n",
    "\n",
    "bd = BayesianData()\n",
    "\n",
    "start_time = datetime.now()\n",
    "logger.info(f\"Starting FAST Feature Selection (n_trials={FAST_N_TRIALS}, n_estimators={FAST_N_ESTIMATORS})...\")\n",
    "\n",
    "# Optional: Start with reduced feature set if you want even faster iteration\n",
    "drops = ['Shoulder_IQR_vel_angle', 'Ankle_IQRaccx', 'Wrist_IQRaccx', 'Ankle_IQRvelx', \n",
    "         'Knee_IQR_vel_angle', 'Elbow_IQR_acc_angle', 'Shoulder_mean_angle', 'Ankle_IQRaccy', \n",
    "         'Shoulder_lrCorr_angle', 'Hip_entropy_angle', 'Elbow_mean_angle', 'Eye_lrCorr_x', \n",
    "         'Shoulder_entropy_angle', 'Knee_entropy_angle', 'Shoulder_IQR_acc_angle', 'Ankle_lrCorr_x', \n",
    "         'Hip_lrCorr_angle', 'Wrist_meanent', 'Wrist_IQRvelx', 'Wrist_mediany', 'Ankle_IQRvely', \n",
    "         'Shoulder_stdev_angle', 'Hip_IQR_acc_angle', 'Elbow_stdev_angle', 'Knee_IQR_acc_angle', \n",
    "         'Ankle_meanent', 'Ankle_medianx', 'Wrist_IQRy', 'Knee_lrCorr_angle', 'Hip_IQR_vel_angle', \n",
    "         'Elbow_IQR_vel_angle', 'Wrist_IQRaccy', 'Wrist_IQRvely', 'Elbow_lrCorr_x']\n",
    "\n",
    "features = FEATURES  # or: [f for f in FEATURES if f not in drops]\n",
    "tot_k = len(features)\n",
    "\n",
    "# Custom RFE function with fast parameters\n",
    "def run_fast_rfe(bd, model_prefix, features, tot_k):\n",
    "    \"\"\"Fast version of run_adaptive_rfe with custom parameters.\"\"\"\n",
    "    import polars as pl\n",
    "    from early_markers.cribsy.common.bayes import BayesianRfeResult\n",
    "    \n",
    "    if bd._frames is None:\n",
    "        raise AttributeError(\"DataFrames are not set.\")\n",
    "    \n",
    "    frames = bd._frames.get(bd.base_model_name)\n",
    "    if frames is None:\n",
    "        raise AttributeError(f\"Base DataFrames are not set.\")\n",
    "    \n",
    "    df_raw = frames.train\n",
    "    df_surprise = frames.train_surprise\n",
    "    \n",
    "    df_rfe = df_raw.join(df_surprise, on=\"infant\", how=\"inner\").sort([\"infant\", \"feature\"]).filter(pl.col(\"feature\").is_in(features))\n",
    "    \n",
    "    # Generate training samples for RFE\n",
    "    df_x = df_rfe.pivot(index='infant', on='feature', values='value').drop(\"infant\").to_pandas()\n",
    "    y = df_rfe.group_by('infant', maintain_order=True).agg(pl.col('z').first()).select(\"z\").to_pandas()[\"z\"]\n",
    "    \n",
    "    in_time = datetime.now()\n",
    "    pct = RFE_KEEP_PCT - (1 - len(features)/tot_k) / 2\n",
    "    \n",
    "    while True:\n",
    "        # Use FAST parameters\n",
    "        selector = EnhancedAdaptiveRFE(\n",
    "            n_trials=FAST_N_TRIALS,        # Fast: 10 instead of 50\n",
    "            alpha=RFE_ALPHA,                # Keep same statistical threshold\n",
    "            n_estimators=FAST_N_ESTIMATORS  # Fast: 100 instead of 200\n",
    "        )\n",
    "        selector.fit(df_x, y, pct)\n",
    "        new_features = selector.get_significant_features()\n",
    "        \n",
    "        if len(new_features) == len(features):\n",
    "            pct -= 0.1\n",
    "            if pct < 0.1:\n",
    "                break\n",
    "            logger.debug(f\"No reduction. Adjusting target pct to {pct:0.2f}\")\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    out_time = datetime.now()\n",
    "    logger.info(f\"Selected {len(new_features)} features in {(out_time - in_time).seconds / 60: 0.2f} minutes\")\n",
    "    \n",
    "    rfe_name = f\"{model_prefix}_k_{len(new_features)}\"\n",
    "    if bd._rfes is None:\n",
    "        bd._rfes = {}\n",
    "    bd._rfes[rfe_name] = result = BayesianRfeResult(\n",
    "        name=rfe_name,\n",
    "        k=len(new_features),\n",
    "        features=new_features,\n",
    "    )\n",
    "    bd.run_surprise_with_features(model_prefix, result.features)\n",
    "    return result.features\n",
    "\n",
    "# Main loop\n",
    "tick = 1\n",
    "iteration_times = []\n",
    "\n",
    "while True:\n",
    "    iter_start = datetime.now()\n",
    "    logger.info(f\"\\n{'='*60}\")\n",
    "    logger.info(f\"Iteration {tick}: Starting with {len(features)} features\")\n",
    "    logger.info(f\"{'='*60}\")\n",
    "    \n",
    "    # Run RFE\n",
    "    features = run_fast_rfe(bd, \"real\", features, tot_k)\n",
    "    \n",
    "    # Run surprise\n",
    "    logger.debug(\"Computing surprise scores...\")\n",
    "    bd.run_surprise_with_features(\"real\", features, overwrite=True)\n",
    "    \n",
    "    # Compute ROC metrics\n",
    "    logger.debug(\"Computing ROC metrics...\")\n",
    "    metrics = bd.compute_roc_metrics(\"real\", len(features))\n",
    "    \n",
    "    iter_time = (datetime.now() - iter_start).seconds / 60\n",
    "    iteration_times.append(iter_time)\n",
    "    logger.info(f\"Iteration {tick} complete: {len(features)} features in {iter_time:.2f} minutes\")\n",
    "    \n",
    "    tick += 1\n",
    "    if len(features) <= MIN_K:\n",
    "        logger.info(f\"Reached minimum feature count ({MIN_K}). Stopping.\")\n",
    "        break\n",
    "\n",
    "stop_time = datetime.now()\n",
    "total_time = (stop_time - start_time).seconds / 60\n",
    "logger.info(f\"\\n{'='*60}\")\n",
    "logger.info(f\"COMPLETE: Feature selection finished in {total_time:.2f} minutes\")\n",
    "logger.info(f\"Iterations: {tick-1}\")\n",
    "logger.info(f\"Average time per iteration: {sum(iteration_times)/len(iteration_times):.2f} minutes\")\n",
    "logger.info(f\"Final feature count: {len(features)}\")\n",
    "logger.info(f\"{'='*60}\")\n",
    "\n",
    "# Generate report\n",
    "logger.info(\"Generating Excel report...\")\n",
    "bd.write_excel_report(\"real\")\n",
    "\n",
    "# Save results\n",
    "logger.info(\"Saving results...\")\n",
    "with open(PKL_DIR / \"bd_real_fast.pkl\", \"wb\") as f:\n",
    "    pickle.dump(bd, f)\n",
    "\n",
    "# Summary statistics\n",
    "l = [f for m in bd.metrics_names for f in bd.metrics(m).features]\n",
    "print(f\"\\nAll Features in Models: {len(l)}\")\n",
    "keeps = list(set(l))\n",
    "print(f\"Deduped Features: {len(keeps)}\")\n",
    "keeps.sort()\n",
    "print(f\"\\nSelected Features:\\n{keeps}\")\n",
    "\n",
    "print(f\"\\nBase Features not in Dropped:\\n{[f for f in bd.base_features if f not in drops]}\")\n",
    "\n",
    "common = [f for f in keeps if f in bd.base_features]\n",
    "common.extend([f for f in bd.base_features if f in keeps])\n",
    "common = sorted(list(set(common)))\n",
    "print(f\"\\nCommon features ({len(common)}):\\n{common}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section_12_id",
   "metadata": {},
   "source": [
    "## 1.2 Iterative Feature Selection Loop\n",
    "\n",
    "The main loop iteratively refines the feature set using a 3-step algorithm until reaching `MIN_K = 10` features.\n",
    "\n",
    "**Algorithm Flow (per iteration):**\n",
    "\n",
    "1. **Feature Selection** (`run_fast_rfe`):\n",
    "   - Creates `EnhancedAdaptiveRFE` selector with fast parameters\n",
    "   - Runs 10 parallel trials (each with 15-fold cross-validation)\n",
    "   - Uses binomial test (\u03b1 = 0.05) to identify statistically significant features\n",
    "   - Target: Keep 90% of features (adjusted dynamically)\n",
    "   - Returns list of significant features\n",
    "\n",
    "2. **Surprise Computation** (`run_surprise_with_features`):\n",
    "   - Computes Bayesian surprise scores for each infant\n",
    "   - Calculates negative log-likelihood: `minus_log_p = \u03a3(-log P_i)` across selected features\n",
    "   - Standardizes to z-scores: `z = (minus_log_p - \u03bc_train) / \u03c3_train`\n",
    "   - Converts to p-values: `p = 2 * SF(|z|)` where SF is survival function\n",
    "   - Higher z-scores indicate greater deviation from normative patterns\n",
    "\n",
    "3. **Metrics Evaluation** (`compute_roc_metrics`):\n",
    "   - **Note**: This is the legacy method name; target API is `run_metrics_from_surprise()`\n",
    "   - Computes ROC curve analysis on test data\n",
    "   - Calculates AUC, sensitivity, specificity at optimal threshold\n",
    "   - Stores metrics for Excel report generation\n",
    "\n",
    "**Convergence Criteria:**\n",
    "- Loop terminates when `len(features) <= MIN_K` (7 features)\n",
    "- Each iteration typically reduces features by 10-30%\n",
    "- Fast mode: Expected 5-10 minutes total runtime\n",
    "- Standard mode would take 30-60 minutes with same convergence path\n",
    "\n",
    "**Performance Tracking:**\n",
    "- `iteration_times` list records duration of each iteration\n",
    "- Average time per iteration logged at completion\n",
    "- Total runtime calculated from start to stop time\n",
    "\n",
    "**Typical Fast Mode Performance:**\n",
    "- 8-10 iterations to reach MIN_K\n",
    "- ~0.5-1.5 minutes per iteration\n",
    "- Feature progression similar to standard mode but with slightly more variability\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section_13_id",
   "metadata": {},
   "source": [
    "## 1.3 Results Export and Analysis\n",
    "\n",
    "This section exports results and provides summary statistics for the fast feature selection run.\n",
    "\n",
    "**Excel Report Generation:**\n",
    "- `write_excel_report(\"real\")` creates formatted workbook: `real_*.xlsx`\n",
    "- Output location: `/Volumes/secure/data/early_markers/cribsy/xlsx/`\n",
    "- Contains multiple sheets:\n",
    "  - **Summary**: Overall metrics across all models\n",
    "  - **Detail**: Per-infant results with z-scores and p-values\n",
    "  - **ROC**: Sensitivity/specificity at various thresholds\n",
    "  - **Features**: Selected features for each model\n",
    "\n",
    "**Pickle Serialization:**\n",
    "- Saves complete `BayesianData` object to `bd_real_fast.pkl`\n",
    "- Location: `/Volumes/secure/data/early_markers/cribsy/pkl/`\n",
    "- Contains all computed results:\n",
    "  - RFE results (`_rfes` dictionary)\n",
    "  - Surprise scores (`_surprise` dictionary)\n",
    "  - ROC metrics (`_metrics` dictionary)\n",
    "  - Base DataFrames (`_base`, `_base_train`, `_base_test`)\n",
    "- Can be loaded in subsequent notebooks for downstream analysis\n",
    "\n",
    "**Summary Statistics:**\n",
    "- **All Features in Models**: Total features across all iterations (with duplicates)\n",
    "- **Deduped Features**: Unique features that appeared in any model\n",
    "- **Selected Features**: Sorted list of final feature names\n",
    "- **Common Features**: Intersection with base model features\n",
    "\n",
    "**Interpretation:**\n",
    "- Fast mode results should be validated against standard mode\n",
    "- Feature lists should be similar (70-90% overlap expected)\n",
    "- ROC metrics may differ by \u00b10.02-0.05 AUC points\n",
    "- For publication/production, always re-run with standard parameters (50 trials, 200 estimators)\n",
    "\n",
    "**Next Steps:**\n",
    "- Compare with `bd_real.pkl` from `01_rfe_real.ipynb` (standard mode)\n",
    "- Validate feature stability across modes\n",
    "- If results diverge significantly, use standard mode results\n",
    "- Use fast mode primarily for development and rapid iteration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "notes_id",
   "metadata": {},
   "source": [
    "## 1.4 Performance Notes\n",
    "\n",
    "### Speed vs. Accuracy Trade-off\n",
    "\n",
    "| Configuration | N Trials | N Estimators | Total Models | Approx Time | Use Case |\n",
    "|---------------|----------|--------------|--------------|-------------|----------|\n",
    "| **Fast** (this notebook) | 10 | 100 | 15,000 | 5-10 min | Development, iteration |\n",
    "| **Standard** (original) | 50 | 200 | 150,000 | 30-60 min | Production, final results |\n",
    "| **Ultra-fast** (testing) | 5 | 50 | 3,750 | 2-3 min | Quick tests only |\n",
    "\n",
    "### Additional Optimizations\n",
    "\n",
    "1. **Pre-filter features**: Start with a reduced feature set (uncomment the `drops` filtering)\n",
    "2. **Adjust MIN_K**: Set a higher minimum feature count to stop earlier\n",
    "3. **Parallel jobs**: The code uses `RFE_N_JOBS=12` by default - adjust in constants.py\n",
    "4. **Single iteration**: For quick testing, run only one iteration instead of the full loop\n",
    "\n",
    "### Validation\n",
    "\n",
    "After running the fast version:\n",
    "- Features should still pass statistical significance tests (binomial test, p < 0.05)\n",
    "- Check ROC metrics are reasonable\n",
    "- For final publication, re-run with standard parameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}