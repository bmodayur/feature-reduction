{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "doc-main-summary",
   "metadata": {},
   "source": [
    "# 3 - Synthetic Data: Feature Selection and Validation\n",
    "\n",
    "**Purpose**: This notebook performs feature selection on synthetically generated infant movement data to validate the robustness and stability of the Enhanced Adaptive RFE algorithm. Synthetic data allows us to test the methodology with known ground truth and assess generalizability.\n",
    "\n",
    "**Inputs**:\n",
    "- Synthetic movement data: `/Volumes/secure/data/early_markers/cribsy/ipc/synth_sdv_1000_long.ipc`\n",
    "  - Generated via SDV (Synthetic Data Vault) from real data distributions\n",
    "  - Stored in Apache Arrow IPC format for efficient Polars processing\n",
    "  - Contains 1000 synthetic infant records with realistic feature distributions\n",
    "- Sample sizes: `TRAIN_N=300`, `TEST_N=100` (configurable)\n",
    "- Previously saved BayesianData object (if available) for comparison\n",
    "\n",
    "**Outputs**:\n",
    "- `/Volumes/secure/data/early_markers/cribsy/pkl/db_train300_test100.pkl` - Complete BayesianData object\n",
    "- `/Volumes/secure/data/early_markers/cribsy/xlsx/synthetic_train300_test100*.xlsx` - Excel reports\n",
    "- Console output showing RFE progression on synthetic data\n",
    "\n",
    "**Key Dependencies**:\n",
    "- `BayesianData`: Core class with synthetic data support via `.ipc` files\n",
    "- `EnhancedAdaptiveRFE`: Statistical feature selection (imported but not directly used)\n",
    "- `Polars`: High-performance DataFrame library for `.ipc` file I/O\n",
    "- Random seed: `RAND_STATE = 20250313` for reproducibility\n",
    "\n",
    "**Workflow Overview**:\n",
    "1. Load previously saved synthetic BayesianData (if exists) and generate report\n",
    "2. Initialize fresh BayesianData with synthetic `.ipc` data\n",
    "3. Apply iterative Enhanced Adaptive RFE until convergence\n",
    "4. Compute Bayesian surprise and ROC metrics at each iteration\n",
    "5. Export comprehensive results for comparison with real data analysis\n",
    "\n",
    "**Synthetic Data Advantages**:\n",
    "- **Known distributions**: Validate algorithm against expected statistical properties\n",
    "- **Controlled sample sizes**: Test performance with varying training/test splits\n",
    "- **Reproducibility**: Generate unlimited data for robustness testing\n",
    "- **Privacy preservation**: No PHI/PII exposure during development\n",
    "- **Algorithm validation**: Compare synthetic vs. real data feature selection stability\n",
    "\n",
    "**Performance**: Typically ~1.5 minutes per iteration (faster than real data due to smaller feature sets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "doc-section-1",
   "metadata": {},
   "source": [
    "## 3.1 - Environment Setup and Prior Results Export\n",
    "\n",
    "This section initializes the analysis environment and exports any previously generated results:\n",
    "\n",
    "### Import Configuration\n",
    "- **Polars imports**: `DataFrame` and `pl` for efficient `.ipc` file handling\n",
    "  - Polars is significantly faster than Pandas for large synthetic datasets\n",
    "  - Native support for Apache Arrow IPC format used by SDV\n",
    "- **Progress tracking**: `tqdm` for visual progress bars during long operations\n",
    "- **Constants**: \n",
    "  - `IPC_DIR`: Directory for Apache Arrow IPC files (`/Volumes/secure/data/early_markers/cribsy/ipc/`)\n",
    "  - `PKL_DIR`: Directory for pickle files\n",
    "\n",
    "### Sample Size Configuration\n",
    "```python\n",
    "TRAIN_N = 300  # Training set size (normative + at-risk)\n",
    "TEST_N = 100   # Test set size (held-out at-risk)\n",
    "```\n",
    "\n",
    "These parameters control the train/test split from the 1000-record synthetic dataset:\n",
    "- Training data is used to compute reference distributions for Bayesian surprise\n",
    "- Test data evaluates out-of-sample performance\n",
    "- Different splits can be tested by modifying `TRAIN_N` and `TEST_N`\n",
    "\n",
    "### Prior Results Handling\n",
    "The notebook first attempts to load and export results from a previous run:\n",
    "```python\n",
    "with open(PKL_DIR / f\"db_train{TRAIN_N}_test{TEST_N}.pkl\", \"rb\") as f:\n",
    "    bd = pickle.load(f)\n",
    "bd.write_excel_report(f\"synthetic_train{TRAIN_N}_test{TEST_N}\")\n",
    "```\n",
    "\n",
    "This allows:\n",
    "- Quick report regeneration without re-running expensive RFE\n",
    "- Comparison of results across different analysis runs\n",
    "- Incremental workflow: export → analyze → modify → re-export"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-05T23:21:40.806000Z",
     "start_time": "2025-10-05T23:21:40.753144Z"
    }
   },
   "source": [
    "from datetime import datetime\n",
    "import pickle\n",
    "\n",
    "from numpy import random\n",
    "from polars import DataFrame\n",
    "import polars as pl\n",
    "from tqdm import tqdm\n",
    "from loguru import logger\n",
    "\n",
    "from early_markers.cribsy.common.bayes import BayesianData\n",
    "from early_markers.cribsy.common.adaptive_rfe import EnhancedAdaptiveRFE, validation_report\n",
    "from early_markers.cribsy.common.constants import AGE_BRACKETS, MIN_K, IPC_DIR, PKL_DIR\n",
    "from early_markers.cribsy.common.constants import RAND_STATE\n",
    "\n",
    "# Configure sample sizes for synthetic data split\n",
    "TRAIN_N = 300  # Training set: normative + at-risk samples\n",
    "TEST_N = 100   # Test set: held-out at-risk samples\n",
    "\n",
    "# Set seeds at file level for reproducibility\n",
    "random.seed(RAND_STATE)\n",
    "\n",
    "# Export report from previously saved BayesianData (if exists)\n",
    "with open(PKL_DIR / f\"db_train{TRAIN_N}_test{TEST_N}.pkl\", \"rb\") as f:\n",
    "    bd = pickle.load(f)\n",
    "\n",
    "bd.write_excel_report(f\"synthetic_train{TRAIN_N}_test{TEST_N}\")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "doc-section-2",
   "metadata": {},
   "source": [
    "## 3.2 - Synthetic Data Loading and Iterative Feature Selection\n",
    "\n",
    "This section loads synthetic data from `.ipc` format and performs iterative feature selection:\n",
    "\n",
    "### Synthetic Data Initialization\n",
    "```python\n",
    "bd = BayesianData(base_file=\"synth_sdv_1000_long.ipc\", \n",
    "                  train_n=TRAIN_N, \n",
    "                  test_n=TEST_N, \n",
    "                  augment=True)\n",
    "```\n",
    "\n",
    "**Key parameters**:\n",
    "- `base_file`: Synthetic data in Apache Arrow IPC format\n",
    "  - Generated by `02_synthetic_sdv.ipynb` using SDV library\n",
    "  - Long format: `infant | category | risk | feature | value`\n",
    "  - Polars automatically handles `.ipc` extension for efficient loading\n",
    "- `train_n=300`: Randomly samples 300 records for training distribution\n",
    "- `test_n=100`: Randomly samples 100 at-risk records for testing\n",
    "- `augment=True`: Enables data augmentation if needed\n",
    "\n",
    "### Convergence-Based Iteration\n",
    "Unlike the real data notebook (fixed `MIN_K=7`), this uses **convergence detection**:\n",
    "```python\n",
    "features_out = tot_k + 1  # Initialize to force first iteration\n",
    "while True:\n",
    "    features_in = len(features)\n",
    "    if features_in == features_out:\n",
    "        break  # Converged: no features removed\n",
    "```\n",
    "\n",
    "**Convergence logic**:\n",
    "- Stops when RFE selects the same features as input\n",
    "- Indicates feature set has stabilized\n",
    "- More adaptive than fixed `MIN_K` threshold\n",
    "- Typical result: Converges at 22 features from 23 starting features\n",
    "\n",
    "### RFE Iteration Steps\n",
    "Same 3-step process as real data analysis:\n",
    "1. **Enhanced Adaptive RFE**: `bd.run_adaptive_rfe(prefix, features, tot_k)`\n",
    "   - Uses model prefix `syn_trn300_tst100` for result tracking\n",
    "   - Applies 50 parallel trials with noise injection\n",
    "   - Statistical significance testing (α=0.05)\n",
    "\n",
    "2. **Bayesian Surprise**: `bd.run_surprise_with_features(prefix, features, overwrite=True)`\n",
    "   - Computes surprise scores using selected features\n",
    "   - `overwrite=True`: Replaces previous iteration's results\n",
    "\n",
    "3. **ROC Metrics**: `bd.compute_roc_metrics(prefix, len(features))`\n",
    "   - Evaluates sensitivity, specificity, AUC\n",
    "   - Indexed by feature count for comparison\n",
    "\n",
    "### Performance Characteristics\n",
    "- **Per iteration**: ~1.45 minutes (faster than real data)\n",
    "  - Smaller feature set (23 vs. 57 features)\n",
    "  - Controlled sample sizes (300+100 vs. full dataset)\n",
    "- **Typical convergence**: 1 iteration for well-conditioned synthetic data\n",
    "\n",
    "### Method Name Note\n",
    "⚠️ **LEGACY METHODS**: Uses `run_adaptive_rfe()` and `compute_roc_metrics()`\n",
    "- Current API: `run_rfe_on_base()`, `run_metrics_from_surprise()`\n",
    "- Should be updated in future revisions"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T23:23:08.339084Z",
     "start_time": "2025-10-05T23:21:40.753144Z"
    }
   },
   "source": [
    "# Initialize BayesianData with synthetic data from .ipc file\n",
    "bd = BayesianData(base_file=\"synth_sdv_1000_long.ipc\", train_n=TRAIN_N, test_n=TEST_N, augment=True)\n",
    "\n",
    "start_time = datetime.now()\n",
    "logger.debug(f\"Starting Feature Selection...\")\n",
    "\n",
    "# Model prefix for tracking synthetic data results\n",
    "prefix = f\"syn_trn{TRAIN_N}_tst{TEST_N}\"\n",
    "features = bd.base_features  # Start with all synthetic data features\n",
    "tot_k = len(features)\n",
    "\n",
    "# Initialize convergence detection\n",
    "tick = 1\n",
    "features_out = tot_k + 1  # Force first iteration\n",
    "\n",
    "# Iterate until convergence (features_in == features_out)\n",
    "while True:\n",
    "    features_in = len(features)\n",
    "    \n",
    "    # Check convergence: stop if no features removed\n",
    "    if features_in == features_out:\n",
    "        break\n",
    "    \n",
    "    logger.debug(f\"Trial {tick}: Features in: {features_in}...\")\n",
    "    \n",
    "    # Step A: Enhanced Adaptive RFE with statistical significance testing\n",
    "    logger.debug(f\"Running adaptive RFE...\")\n",
    "    features = bd.run_adaptive_rfe(prefix, features, tot_k=tot_k)\n",
    "    features_out = len(features)\n",
    "    \n",
    "    # Step B: Compute Bayesian surprise using selected features\n",
    "    logger.debug(f\"Running surprise...\")\n",
    "    bd.run_surprise_with_features(prefix, features, overwrite=True)\n",
    "    \n",
    "    # Step C: Evaluate ROC performance\n",
    "    logger.debug(f\"Computing ROC...\")\n",
    "    metrics = bd.compute_roc_metrics(prefix, len(features))\n",
    "\n",
    "    logger.debug(f\"...Trial {tick}: Features out: {len(features)}.\")\n",
    "    tick += 1\n",
    "    \n",
    "    # Safety termination: stop if reaching minimum threshold\n",
    "    if len(features) <= MIN_K:\n",
    "        break\n",
    "\n",
    "stop_time = datetime.now()\n",
    "logger.debug(f\"Completed Feature Selection in {(stop_time - start_time).seconds / 60: 0.2f} Minutes.\")"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "doc-section-3",
   "metadata": {},
   "source": [
    "## 3.3 - Results Export and Persistence\n",
    "\n",
    "This section exports comprehensive results from the synthetic data analysis:\n",
    "\n",
    "### Excel Report Generation\n",
    "```python\n",
    "bd.write_excel_report(f\"synthetic_train{TRAIN_N}_test{TEST_N}_rfe\")\n",
    "```\n",
    "\n",
    "**Output location**: `/Volumes/secure/data/early_markers/cribsy/xlsx/synthetic_train300_test100_rfe*.xlsx`\n",
    "\n",
    "**Report contents**:\n",
    "- **Summary sheet**: Aggregate metrics across all RFE iterations\n",
    "- **Detail sheets**: Per-iteration ROC curves and feature lists\n",
    "- **Feature progression**: Shows which features were retained at each step\n",
    "- **Performance comparison**: Sensitivity, specificity, AUC by feature count\n",
    "\n",
    "### BayesianData Persistence\n",
    "```python\n",
    "with open(PKL_DIR / f\"db_train{TRAIN_N}_test{TEST_N}.pkl\", \"wb\") as f:\n",
    "    pickle.dump(bd, f)\n",
    "```\n",
    "\n",
    "**Saved object contents**:\n",
    "- Complete `BayesianData` instance with all computed results\n",
    "- All RFE iterations and selected feature sets\n",
    "- Bayesian surprise metrics for each infant\n",
    "- ROC performance metrics across all iterations\n",
    "- Training and test data splits\n",
    "\n",
    "**Usage in downstream analyses**:\n",
    "- Load for quick report regeneration (as shown in Section 3.1)\n",
    "- Compare synthetic vs. real data feature stability\n",
    "- Validate algorithm performance on known distributions\n",
    "- Test different sample size configurations\n",
    "\n",
    "### Synthetic vs. Real Data Comparison\n",
    "To compare results with real data analysis:\n",
    "```python\n",
    "# Load real data results\n",
    "with open(PKL_DIR / \"bd_real.pkl\", 'rb') as f:\n",
    "    bd_real = pickle.load(f)\n",
    "\n",
    "# Load synthetic data results\n",
    "with open(PKL_DIR / \"db_train300_test100.pkl\", 'rb') as f:\n",
    "    bd_synthetic = pickle.load(f)\n",
    "\n",
    "# Compare selected features\n",
    "real_features = bd_real.rfe_features(\"real\")\n",
    "synth_features = bd_synthetic.rfe_features(\"syn_trn300_tst100\")\n",
    "common_features = set(real_features) & set(synth_features)\n",
    "```\n",
    "\n",
    "### Validation Metrics\n",
    "Expected outcomes for well-performing synthetic data:\n",
    "- **Feature overlap**: 60-80% common features between real and synthetic\n",
    "- **Convergence speed**: Faster convergence indicates clean synthetic distributions\n",
    "- **ROC performance**: Similar AUC values suggest good distribution matching\n",
    "- **Feature stability**: Consistent selections across multiple synthetic runs\n",
    "\n",
    "### Next Steps\n",
    "After running this notebook:\n",
    "1. Compare Excel reports: `real_*.xlsx` vs. `synthetic_*.xlsx`\n",
    "2. Validate feature selection consistency\n",
    "3. Assess synthetic data quality for algorithm development\n",
    "4. Consider generating additional synthetic datasets with different parameters"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T23:23:08.339084Z",
     "start_time": "2025-10-05T23:23:08.313000Z"
    }
   },
   "source": [
    "# Export comprehensive Excel report with RFE results\n",
    "bd.write_excel_report(f\"synthetic_train{TRAIN_N}_test{TEST_N}_rfe\")\n",
    "\n",
    "# Serialize complete BayesianData object for downstream analysis and comparison\n",
    "with open(PKL_DIR / f\"db_train{TRAIN_N}_test{TEST_N}.pkl\", \"wb\") as f:\n",
    "    pickle.dump(bd, f)"
   ],
   "outputs": [],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
