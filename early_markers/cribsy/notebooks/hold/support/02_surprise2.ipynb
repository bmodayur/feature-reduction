{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "doc-main-summary",
   "metadata": {},
   "source": [
    "# 02 - Bayesian Surprise and Feature Selection\n",
    "\n",
    "**Purpose**: This notebook is the analytical core of the project. It orchestrates the main feature selection and Bayesian surprise analysis pipeline on both real and synthetic data. It iteratively reduces the feature set and evaluates model performance at each step.\n",
    "\n",
    "**Inputs**:\n",
    "- Real data, accessed by instantiating the `BayesianData` class with default parameters.\n",
    "- Synthetic data (`synth_sdv_1000_long.ipc`), used in the second half of the notebook.\n",
    "\n",
    "**Outputs**:\n",
    "- `bd_real.pkl`: A pickled `BayesianData` object containing the complete state of the analysis on real data (feature lists, surprise scores, ROC metrics).\n",
    "- `db_train{N}_test{N}.pkl`: A pickled `BayesianData` object for the synthetic data analysis.\n",
    "- Excel reports (`real_report.xlsx`, `synthetic_...xlsx`) summarizing the performance of models at each stage of feature reduction.\n",
    "\n",
    "### Key Sections:\n",
    "1.  **Developer Notes**: Initial thoughts and a checklist from the development process.\n",
    "2.  **Analysis on Real Data**: An iterative loop that:\n",
    "    a. Runs `EnhancedAdaptiveRFE` to find the best features.\n",
    "    b. Computes Bayesian surprise scores with the selected features.\n",
    "    c. Calculates ROC metrics to evaluate performance.\n",
    "    d. Reduces the feature set and repeats until a minimum number of features is reached.\n",
    "3.  **Analysis on Synthetic Data**: Repeats the same iterative process on a synthetic dataset to validate the methodology.\n",
    "4.  **Result Aggregation**: Consolidates and prints the final selected feature sets."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T21:02:02.908246Z",
     "start_time": "2025-10-04T21:02:02.904039Z"
    }
   },
   "cell_type": "markdown",
   "source": [
    "### 2.1 PEB 2025.03.27 21:06 =>\n",
    "- [X] Remove features_38... nothing special.\n",
    "- [X] Do not define max features statically.\n",
    "- [X] Set age_bracket [1,2] using >= 6 threshold (B)\n",
    "- [X] Set risk in [0,1] using threshold >= 2 (B)\n",
    "- [X] Set category in [1,2] using thresholds category == 0 or risk == 0\n",
    "- [X] Random sample n=40 of risk==0 && category==1 and assign category to 2\n",
    "- [X] Drop infant clin_100_6\n",
    "- [X] Produce a TRAIN set size of 94 and TEST set size of 54\n",
    "- [X] RFE for 20 features and test\n",
    "\n",
    "Create synthetic data on risk in [0,1].\n",
    "Ensure Synthetic training and testing data have 90/10, 85/15 ratios of risk 0/1\n",
    "Setup for cross validation and feature selection to arrive at optimal estimates\n"
   ],
   "id": "ead2117d2faf936c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Enhanced Adaptive RFE on Real Data",
   "id": "c6a7c42d47b0233d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2.2 Iterative RFE and Surprise Analysis on Real Data\n",
    "\n",
    "This is the main computational cell for the analysis of real-world data. It performs an iterative feature selection and evaluation loop:\n",
    "1.  **Initialization**: Sets the global random seed, instantiates the `BayesianData` class (loading real data by default), and initializes the feature list.\n",
    "2.  **Iterative Loop**: Continuously loops until the number of features is reduced to `MIN_K` (a predefined constant).\n",
    "3.  **Run RFE**: In each iteration, it calls `bd.run_adaptive_rfe()` to perform Enhanced Adaptive RFE on the current feature set.\n",
    "4.  **Run Surprise**: The reduced feature set is then used to compute Bayesian surprise scores via `bd.run_surprise_with_features()`.5.  **Compute Metrics**: `bd.compute_roc_metrics()` is called to evaluate the diagnostic performance of the model with the current feature set.6.  **Log Progress**: `loguru` is used to log the number of features and progress at each trial.\n",
    "7.  **Final Report**: After the loop terminates, `bd.write_excel_report()` is called to generate a comprehensive Excel spreadsheet summarizing the results from all iterations."
   ],
   "id": "a207cbe756e2e950"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from numpy import random\n",
    "from polars import DataFrame\n",
    "import polars as pl\n",
    "from tqdm import tqdm\n",
    "from loguru import logger\n",
    "\n",
    "from early_markers.cribsy.common.bayes import BayesianData\n",
    "from early_markers.cribsy.common.adaptive_rfe import EnhancedAdaptiveRFE, validation_report\n",
    "from early_markers.cribsy.common.constants import AGE_BRACKETS, MIN_K, PKL_DIR, FEATURES\n",
    "\n",
    "from early_markers.cribsy.common.constants import RAND_STATE\n",
    "\n",
    "\n",
    "# Set seeds at file level\n",
    "random.seed(RAND_STATE)\n",
    "\n",
    "bd = BayesianData()\n",
    "\n",
    "start_time = datetime.now()\n",
    "logger.debug(f\"Starting Feature Selection...\")\n",
    "# features = bd.base_features\n",
    "drops = ['Shoulder_IQR_vel_angle', 'Ankle_IQRaccx', 'Wrist_IQRaccx', 'Ankle_IQRvelx', 'Knee_IQR_vel_angle', 'Elbow_IQR_acc_angle', 'Shoulder_mean_angle', 'Ankle_IQRaccy', 'Shoulder_lrCorr_angle', 'Hip_entropy_angle', 'Elbow_mean_angle', 'Eye_lrCorr_x', 'Shoulder_entropy_angle', 'Knee_entropy_angle', 'Shoulder_IQR_acc_angle', 'Ankle_lrCorr_x', 'Hip_lrCorr_angle', 'Wrist_meanent', 'Wrist_IQRvelx', 'Wrist_mediany', 'Ankle_IQRvely', 'Shoulder_stdev_angle', 'Hip_IQR_acc_angle', 'Elbow_stdev_angle', 'Knee_IQR_acc_angle', 'Ankle_meanent', 'Ankle_medianx', 'Wrist_IQRy', 'Knee_lrCorr_angle', 'Hip_IQR_vel_angle', 'Elbow_IQR_vel_angle', 'Wrist_IQRaccy', 'Wrist_IQRvely', 'Elbow_lrCorr_x']\n",
    "features = FEATURES  # bd.base_features  # [f for f in bd.base_features if f not in drops]\n",
    "tot_k = len(features)\n",
    "tick = 1\n",
    "while True:\n",
    "    logger.debug(f\"Trial {tick}: Features in: {len(features)}...\")\n",
    "    features = bd.run_adaptive_rfe(\"real\", features, tot_k)\n",
    "    bd.run_surprise_with_features(\"real\", features, overwrite=True)\n",
    "    metrics = bd.compute_roc_metrics(\"real\", len(features))\n",
    "    logger.debug(f\"...Trial {tick}: Features out: {len(features)}.\")\n",
    "    tick += 1\n",
    "    if len(features) <= MIN_K:\n",
    "        break\n",
    "stop_time = datetime.now()\n",
    "logger.debug(f\"Completed Feature Selection in {(stop_time - start_time).seconds / 60: 0.2f} Minutes.\")\n",
    "bd.write_excel_report(\"real\")"
   ],
   "id": "d5cc31a3b3106a1c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2.3 Persist Analysis State\n",
    "\n",
    "This cell uses `pickle` to save the entire state of the `BayesianData` object (`bd`) to a file named `bd_real.pkl`. This is a critical step for caching results, as it saves all computed metrics, feature lists, and surprise scores, allowing the analysis state to be reloaded in other notebooks without re-running the time-consuming feature selection process."
   ],
   "id": "db4cd323abf6b02"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "\n",
    "with open(PKL_DIR / \"bd_real.pkl\", \"wb\") as f:\n",
    "    pickle.dump(bd, f)"
   ],
   "id": "17d2fbdefe9b755a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2.5 Aggregate and Display Final Feature Sets\n",
    "\n",
    "This cell consolidates the results of the iterative feature selection. It extracts the list of selected features from all the models generated during the loop, de-duplicates them to create a final consensus set (`keeps`), and prints the total counts and the full list of features for review."
   ],
   "id": "f1accfbd78edb3c9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "l = [f for m in bd.metrics_names for f in bd.metrics(m).features ]\n",
    "print(f\"All Features in Models: {len(l)}\")\n",
    "keeps = list(set(l))\n",
    "print(f\"\\nDeduped Features: {len(keeps)}\")\n",
    "keeps.sort()\n",
    "print(f\"\\nDeduped:\\n{keeps}\")\n",
    "\n",
    "print(f\"\\nBase Features not in Dropped:\\n{[f for f in bd.base_features if f not in drops]}\")\n",
    "\n",
    "common = [f for f in keeps if f in bd.base_features]\n",
    "common.extend([f for f in bd.base_features if f in keeps])\n",
    "common = sorted(list(set(common)))\n",
    "print(f\"\\ncommon features ({len(common)}):\\n{common}\")"
   ],
   "id": "de1bfbde9406c174",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2.4 Plan\n",
    "1. Feed reduced feature set to SDV CTGAN model.\n",
    "2. Rerun RFE w Synthetic Data.\n",
    "3. Test With Real Test Data.\n",
    "4. Find N based on CI\n"
   ],
   "id": "f886ac8926aa5267"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2.7 Write Synthetic Data Excel Report\n",
    "\n",
    "This cell loads the pickled `BayesianData` object from the synthetic analysis and calls `write_excel_report()` to generate the final, formatted Excel summary. A key detail is the note about shortening worksheet names to ensure they are `_xlwt` compatible (<= 31 characters)."
   ],
   "id": "b8dc4dc4807decef"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# PEB 2025.04.02 23:21 => shorten worksheet names to <= 32 chars\n",
    "with open(PKL_DIR / f\"db_train{TRAIN_N}_test{TEST_N}.pkl\", \"rb\") as f:\n",
    "    bd = pickle.load(f)\n",
    "\n",
    "bd.write_excel_report(f\"synthetic_train{TRAIN_N}_test{TEST_N}\")"
   ],
   "id": "174ff0c726cd6850",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "\n",
    "from numpy import random\n",
    "from polars import DataFrame\n",
    "import polars as pl\n",
    "from tqdm import tqdm\n",
    "from loguru import logger\n",
    "\n",
    "from early_markers.cribsy.common.bayes import BayesianData\n",
    "from early_markers.cribsy.common.adaptive_rfe import EnhancedAdaptiveRFE, validation_report\n",
    "from early_markers.cribsy.common.constants import AGE_BRACKETS, MIN_K, IPC_DIR, PKL_DIR\n",
    "\n",
    "from early_markers.cribsy.common.constants import RAND_STATE\n",
    "\n",
    "TRAIN_N = 300\n",
    "TEST_N = 100\n",
    "\n",
    "# Set seeds at file level\n",
    "random.seed(RAND_STATE)\n",
    "\n",
    "bd = BayesianData(base_file=\"synth_sdv_1000_long.ipc\", train_n=TRAIN_N, test_n=TEST_N, augment=True)\n",
    "start_time = datetime.now()\n",
    "logger.debug(f\"Starting Feature Selection...\")\n",
    "prefix = f\"syn_trn{TRAIN_N}_tst{TEST_N}\"\n",
    "features = bd.base_features\n",
    "tot_k = len(features)\n",
    "tick = 1\n",
    "# features_in = features_out = tot_k\n",
    "features_out = tot_k + 1\n",
    "while True:\n",
    "    features_in = len(features)\n",
    "    if features_in == features_out:\n",
    "        break\n",
    "    logger.debug(f\"Trial {tick}: Features in: {features_in}...\")\n",
    "    features = bd.run_adaptive_rfe(prefix, features, tot_k=tot_k)\n",
    "    features_out = len(features)\n",
    "    bd.run_surprise_with_features(prefix, features, overwrite=True)\n",
    "    metrics = bd.compute_roc_metrics(prefix, len(features))\n",
    "\n",
    "    logger.debug(f\"...Trial {tick}: Features out: {len(features)}.\")\n",
    "    tick += 1\n",
    "    if len(features) <= MIN_K:\n",
    "        break\n",
    "stop_time = datetime.now()\n",
    "logger.debug(f\"Completed Feature Selection in {(stop_time - start_time).seconds / 60: 0.2f} Minutes.\")\n",
    "\n",
    "with open(PKL_DIR / f\"db_train{TRAIN_N}_test{TEST_N}.pkl\", \"wb\") as f:\n",
    "    pickle.dump(bd, f)\n"
   ],
   "id": "dfc2d296cc829d1f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2.8 Describe Base DataFrame\n",
    "\n",
    "This cell provides a quick summary of the `category` and `risk` columns in the base wide-format DataFrame, allowing for a final check of the data distribution after the synthetic analysis."
   ],
   "id": "e55ffec9bc52562c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_base = bd.base_wide\n",
    "df_base.select(\"category\", \"risk\").describe()"
   ],
   "id": "85d9614c45c38373",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Enhanced Adaptive RFE on Synthetic Data",
   "id": "ae6a2d18a8e87e59"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2.6 Iterative RFE and Surprise Analysis on Synthetic Data\n",
    "\n",
    "This section mirrors the analysis performed on real data, but instead uses a synthetic dataset to validate the feature selection and modeling pipeline. Key differences include:\n",
    "- **Data Source**: It loads a synthetic dataset from an IPC file (`synth_sdv_1000_long.ipc`).\n",
    "- **Subsampling**: It uses `train_n` and `test_n` to work with smaller subsets of the synthetic data (300 training, 100 testing samples).\n",
    "- **Augmentation**: It sets `augment=True` in the `BayesianData` constructor, which may introduce additional noise features to further test the robustness of the RFE process.\n",
    "- **Output Files**: The resulting `BayesianData` object and Excel report are saved with filenames that reflect the synthetic data source and sample sizes used."
   ],
   "id": "3fc01256b4765c25"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# ~Find Minimum Sample Size Requirement~",
   "id": "cdedb504d3dc2932"
  },
  {
   "cell_type": "markdown",
   "id": "doc-cell-9",
   "metadata": {},
   "source": [
    "### 2.9 Placeholder for Minimum Sample Size Analysis\n",
    "\n",
    "This final cell is a placeholder for a potential future analysis to determine the minimum sample size required to achieve a certain level of statistical power or confidence interval width. The commented-out code suggests an iterative approach, looping through different `train_n` and `test_n` values."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# from early_markers.cribsy.common.bayes import BayesianData, BayesianCI\n",
    "#\n",
    "#\n",
    "# random.seed(RAND_STATE)\n",
    "#\n",
    "# ci_metrics = {}\n",
    "#\n",
    "#\n",
    "# for train_n in range(1000, 50, -50):\n",
    "#     for test_n in range(1000, 50 -50):\n",
    "#         bd = BayesianData(base_file=\"synth_long.ipc\", train_n=train_n, test_n=test_n)"
   ],
   "id": "bde1a83daae460cf",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
