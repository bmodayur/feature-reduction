{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "doc-main-summary",
   "metadata": {},
   "source": [
    "# 05 - Synthetic Data Generation with YData\n",
    "\n",
    "**Purpose**: This notebook uses the `ydata-sdk` to generate synthetic data that mimics the statistical properties of the real training and testing datasets. This is a crucial step for model validation, data augmentation, and robustness testing.\n",
    "\n",
    "**Inputs**:\n",
    "- Real data, accessed via the `BayesianData` class, which is then split into training and testing sets.\n",
    "\n",
    "**Outputs**:\n",
    "- `profile_real_train_{date}.html` & `profile_real_test_{date}.html`: `ydata-profiling` reports for the real datasets.\n",
    "- `synth_train.ipc` & `synth_test.ipc`: The generated synthetic datasets, saved in the efficient IPC format.\n",
    "- `synth_train_long.ipc`, `synth_test_long.ipc`, `synth_long.ipc`: The synthetic data reshaped into a long format.\n",
    "\n",
    "### Key Steps:\n",
    "1.  **Profile Real Data**: Generates and saves detailed `ydata-profiling` reports for the real training and testing sets to understand their distributions.\n",
    "2.  **Train Synthesizer**: Fits a `RegularSynthesizer` from `ydata-sdk` on the real training data.\n",
    "3.  **Generate Synthetic Data**: Uses the trained synthesizer to generate a new sample of synthetic data.\n",
    "4.  **Evaluate Synthetic Data**: Creates a `SyntheticDataProfile` to compare the statistical properties of the generated data against the original data, ensuring quality and fidelity.\n",
    "5.  **Save Artifacts**: Saves the generated synthetic data in both wide and long formats to IPC files for use in other notebooks."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Profile Real Data",
   "id": "ee32746d9896a12b"
  },
  {
   "cell_type": "markdown",
   "id": "doc-cell-1",
   "metadata": {},
   "source": [
    "### 5.1 Profile Real Data and Generate Synthetic Data with YData\n",
    "\n",
    "This cell is the core of the notebook, performing a multi-step process to generate synthetic data:\n",
    "1.  **Setup**: Imports libraries, sets the YData license key, and defines constants for the number of synthetic rows to generate.\n",
    "2.  **Load Real Data**: Instantiates `BayesianData` and prepares the wide-format training and testing sets as Pandas DataFrames.\n",
    "3.  **Profile Real Data**: Uses `ydata-profiling` to generate and save detailed HTML reports for both the real training and testing data, which helps in understanding the data's characteristics before synthesis.\n",
    "4.  **Fit Synthesizer**: Trains a `RegularSynthesizer` from the YData SDK on the real training data.\n",
    "5.  **Generate & Profile Synthetic Data**: Samples new data and creates a `SyntheticDataProfile` to compare the generated data with the original data, providing a quality assessment."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import math\n",
    "from datetime import datetime\n",
    "\n",
    "import polars as pl\n",
    "from polars import DataFrame\n",
    "import polars.selectors as cs\n",
    "# from sdv.metadata import Metadata\n",
    "# from sdv.single_table import GaussianCopulaSynthesizer\n",
    "# from sdv.sampling import Condition\n",
    "# from sdv.evaluation.single_table import run_diagnostic, evaluate_quality, get_column_plot\n",
    "import pandas as pd\n",
    "from ydata_profiling import ProfileReport\n",
    "from ydata.dataset import Dataset\n",
    "from ydata.metadata import Metadata\n",
    "from ydata.report import SyntheticDataProfile\n",
    "from ydata.synthesizers.regular.model import RegularSynthesizer\n",
    "\n",
    "# from early_markers.cribsy.common.data import get_dataframes, get_merged_dataframe\n",
    "from early_markers.cribsy.common.constants import JSON_DIR, IPC_DIR, RAND_STATE, FEATURES, HTML_DIR\n",
    "from early_markers.cribsy.common.bayes import BayesianData\n",
    "\n",
    "# Ydata Key: ef3d3f6c-3b14-4309-8b95-e1ef605918fb\n",
    "os.environ['YDATA_LICENSE_KEY'] = '{ef3d3f6c-3b14-4309-8b95-e1ef605918fb}'\n",
    "\n",
    "NUM_ROWS = 2000\n",
    "RISK_0_ROWS = math.ceil(0.740741 * NUM_ROWS)\n",
    "RISK_1_ROWS = NUM_ROWS - RISK_0_ROWS\n",
    "\n",
    "TODAY = datetime.today().strftime(\"%Y%m%d\")\n",
    "\n",
    "bd = BayesianData()\n",
    "\n",
    "cols = [\"infant\", \"category\", \"risk\", \"age_bracket\"] + FEATURES\n",
    "\n",
    "df_train = bd.base_train_wide.select(cols).to_pandas()\n",
    "df_test = bd.base_test_wide.select(cols).to_pandas()\n",
    "\n",
    "\n",
    "rpt_train = ProfileReport(\n",
    "    df_train,\n",
    "    title=\"Real Training Data\",\n",
    "    explorative=True,\n",
    ")\n",
    "rpt_train.to_file(HTML_DIR / f'profile_real_train_{TODAY}.html')\n",
    "\n",
    "rpt_test = ProfileReport(\n",
    "    df_test,\n",
    "    title=\"Real Testing Data\"\n",
    ")\n",
    "rpt_test.to_file(HTML_DIR / f'profile_real_test_{TODAY}.html')\n",
    "\n",
    "meta_train = Metadata(Dataset(df_train))\n",
    "synth_train = RegularSynthesizer()\n",
    "synth_train.fit(df_train, meta_train, random_state=RAND_STATE)\n",
    "sample_train = synth_train.sample(1_000)\n",
    "meta_synth_train = Metadata(sample_train)\n",
    "profile_train = SyntheticDataProfile(\n",
    "    df_train,\n",
    "    sample_train,\n",
    "    metadata=meta_synth_train,\n",
    "    target=\"risk\",\n",
    "    data_types=synth_train.data_types,\n",
    ")"
   ],
   "id": "fac296829b222317",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "doc-cell-2",
   "metadata": {},
   "source": [
    "### 5.2 Configure and Save SDV Metadata\n",
    "\n",
    "This cell configures metadata for the `sdv` (Synthetic Data Vault) library, a different tool for synthetic data generation. It demonstrates the interoperability of the workflow:\n",
    "1.  **Detect Metadata**: Automatically detects the schema and data types from the wide-format DataFrame.\n",
    "2.  **Update Column Type**: Manually overrides the data type for the `risk` column to ensure it is treated as categorical.\n",
    "3.  **Define Distributions**: Specifies the desired statistical distribution for each feature to guide the `GaussianCopulaSynthesizer`.\n",
    "4.  **Add Constraints**: Defines that the `risk` and `category` columns must use fixed combinations observed in the real data.\n",
    "5.  **Fit and Sample**: Fits synthesizers for both training and testing sets and samples new data, enforcing the specified conditions.\n",
    "6.  **Save Data**: Saves the final synthetic datasets to IPC files in both wide and long formats."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "metadata = Metadata.detect_from_dataframe(\n",
    "    data=bd.base_wide.select(cols).to_pandas(),\n",
    "    table_name=\"features\",\n",
    ")\n",
    "metadata.update_column(\n",
    "    column_name=\"risk\",\n",
    "    sdtype = \"categorical\"\n",
    ")\n",
    "metadata.save_to_json(JSON_DIR / \"sdv_metadata.json\", mode=\"overwrite\")\n",
    "\n",
    "\n",
    "distro_train = {\n",
    "    # \"risk_raw\": \"beta\",\n",
    "    # \"category\": \"beta\",\n",
    "    \"Ankle_IQRaccx\": \"gaussian_kde\",\n",
    "    \"Ankle_IQRaccy\": \"gaussian_kde\",\n",
    "    \"Ankle_IQRvelx\": \"gaussian_kde\",\n",
    "    \"Ankle_IQRvely\": \"gaussian_kde\",\n",
    "    \"Ankle_IQRx\": \"norm\",\n",
    "    \"Ankle_IQRy\": \"norm\",\n",
    "    \"Ankle_lrCorr_x\": \"beta\",\n",
    "    \"Ankle_meanent\": \"gaussian_kde\",\n",
    "    \"Ankle_medianvelx\": \"gaussian_kde\",\n",
    "    \"Ankle_medianvely\": \"norm\",\n",
    "    \"Ankle_medianx\": \"norm\",\n",
    "    \"Ankle_mediany\": \"gaussian_kde\",\n",
    "    \"Ear_lrCorr_x\": \"norm\",\n",
    "    \"Elbow_IQR_acc_angle\": \"gaussian_kde\",\n",
    "    \"Elbow_IQR_vel_angle\": \"gaussian_kde\",\n",
    "    \"Elbow_entropy_angle\": \"beta\",\n",
    "    \"Elbow_lrCorr_angle\": \"beta\",\n",
    "    \"Elbow_lrCorr_x\": \"norm\",\n",
    "    \"Elbow_mean_angle\": \"gaussian_kde\",\n",
    "    \"Elbow_median_vel_angle\": \"gaussian_kde\",\n",
    "    \"Elbow_stdev_angle\": \"norm\",\n",
    "    \"Eye_lrCorr_x\": \"norm\",  # ***\n",
    "    \"Hip_IQR_acc_angle\": \"gaussian_kde\",\n",
    "    \"Hip_IQR_vel_angle\": \"gaussian_kde\",\n",
    "    \"Hip_entropy_angle\": \"beta\",\n",
    "    \"Hip_lrCorr_angle\": \"beta\",\n",
    "    # \"Hip_lrCorr_x\": \"gaussian_kde\",  # ***\n",
    "    \"Hip_mean_angle\": \"gaussian_kde\",\n",
    "    \"Hip_median_vel_angle\": \"gaussian_kde\",\n",
    "    \"Hip_stdev_angle\": \"gaussian_kde\",\n",
    "    \"Knee_IQR_acc_angle\": \"gaussian_kde\",\n",
    "    \"Knee_IQR_vel_angle\": \"gaussian_kde\",\n",
    "    \"Knee_entropy_angle\": \"gaussian_kde\",\n",
    "    \"Knee_lrCorr_angle\": \"norm\",\n",
    "    \"Knee_lrCorr_x\": \"gaussian_kde\",\n",
    "    \"Knee_mean_angle\": \"gaussian_kde\",\n",
    "    \"Knee_median_vel_angle\": \"gaussian_kde\",\n",
    "    \"Knee_stdev_angle\": \"beta\",\n",
    "    \"Shoulder_IQR_acc_angle\": \"gaussian_kde\",\n",
    "    \"Shoulder_IQR_vel_angle\": \"gaussian_kde\",\n",
    "    \"Shoulder_entropy_angle\": \"norm\",\n",
    "    \"Shoulder_lrCorr_angle\": \"norm\",\n",
    "    # \"Shoulder_lrCorr_x\": \"beta\",\n",
    "    \"Shoulder_mean_angle\": \"gaussian_kde\",\n",
    "    \"Shoulder_median_vel_angle\": \"beta\",\n",
    "    \"Shoulder_stdev_angle\": \"gaussian_kde\",\n",
    "    \"Wrist_IQRaccx\": \"gaussian_kde\",\n",
    "    \"Wrist_IQRaccy\": \"gaussian_kde\",\n",
    "    \"Wrist_IQRvelx\": \"gaussian_kde\",\n",
    "    \"Wrist_IQRvely\": \"gaussian_kde\",\n",
    "    \"Wrist_IQRx\": \"gaussian_kde\",\n",
    "    \"Wrist_IQRy\": \"gaussian_kde\",\n",
    "    \"Wrist_lrCorr_x\": \"gaussian_kde\", # beta\n",
    "    \"Wrist_meanent\": \"gaussian_kde\",\n",
    "    \"Wrist_medianvelx\": \"gaussian_kde\",\n",
    "    \"Wrist_medianvely\": \"gaussian_kde\",\n",
    "    \"Wrist_medianx\": \"norm\",\n",
    "    \"Wrist_mediany\": \"gaussian_kde\",\n",
    "}\n",
    "\n",
    "distro_test = {\n",
    "    # \"risk_raw\": \"beta\",\n",
    "    # \"category\": \"beta\",\n",
    "    \"Ankle_IQRaccx\": \"gaussian_kde\",\n",
    "    \"Ankle_IQRaccy\": \"gaussian_kde\",\n",
    "    \"Ankle_IQRvelx\": \"gaussian_kde\",\n",
    "    \"Ankle_IQRvely\": \"gaussian_kde\",\n",
    "    \"Ankle_IQRx\": \"gaussian_kde\",\n",
    "    \"Ankle_IQRy\": \"gaussian_kde\",\n",
    "    \"Ankle_lrCorr_x\": \"beta\",\n",
    "    \"Ankle_meanent\": \"gaussian_kde\",\n",
    "    \"Ankle_medianvelx\": \"gaussian_kde\",\n",
    "    \"Ankle_medianvely\": \"gaussian_kde\",\n",
    "    \"Ankle_medianx\": \"gamma\",\n",
    "    \"Ankle_mediany\": \"gaussian_kde\",\n",
    "    \"Ear_lrCorr_x\": \"norm\",\n",
    "    \"Elbow_IQR_acc_angle\": \"gaussian_kde\",\n",
    "    \"Elbow_IQR_vel_angle\": \"gaussian_kde\",\n",
    "    \"Elbow_entropy_angle\": \"gaussian_kde\",\n",
    "    \"Elbow_lrCorr_angle\": \"beta\",\n",
    "    \"Elbow_lrCorr_x\": \"norm\",\n",
    "    \"Elbow_mean_angle\": \"gaussian_kde\",\n",
    "    \"Elbow_median_vel_angle\": \"gaussian_kde\",\n",
    "    \"Elbow_stdev_angle\": \"norm\",\n",
    "    \"Eye_lrCorr_x\": \"gaussian_kde\",  # ***\n",
    "    \"Hip_IQR_acc_angle\": \"gaussian_kde\",\n",
    "    \"Hip_IQR_vel_angle\": \"gaussian_kde\",\n",
    "    \"Hip_entropy_angle\": \"gaussian_kde\",\n",
    "    \"Hip_lrCorr_angle\": \"gaussian_kde\",\n",
    "    # \"Hip_lrCorr_x\": \"gaussian_kde\",  # ***\n",
    "    \"Hip_mean_angle\": \"gaussian_kde\",\n",
    "    \"Hip_median_vel_angle\": \"gaussian_kde\",\n",
    "    \"Hip_stdev_angle\": \"gaussian_kde\",\n",
    "    \"Knee_IQR_acc_angle\": \"gaussian_kde\",\n",
    "    \"Knee_IQR_vel_angle\": \"gaussian_kde\",\n",
    "    \"Knee_entropy_angle\": \"gaussian_kde\",\n",
    "    \"Knee_lrCorr_angle\": \"norm\",\n",
    "    \"Knee_lrCorr_x\": \"gaussian_kde\",\n",
    "    \"Knee_mean_angle\": \"gaussian_kde\",\n",
    "    \"Knee_median_vel_angle\": \"gaussian_kde\",\n",
    "    \"Knee_stdev_angle\": \"beta\",\n",
    "    \"Shoulder_IQR_acc_angle\": \"gaussian_kde\",\n",
    "    \"Shoulder_IQR_vel_angle\": \"gaussian_kde\",\n",
    "    \"Shoulder_entropy_angle\": \"norm\",\n",
    "    \"Shoulder_lrCorr_angle\": \"norm\",\n",
    "    # \"Shoulder_lrCorr_x\": \"beta\",\n",
    "    \"Shoulder_mean_angle\": \"gaussian_kde\",\n",
    "    \"Shoulder_median_vel_angle\": \"beta\",\n",
    "    \"Shoulder_stdev_angle\": \"gaussian_kde\",\n",
    "    \"Wrist_IQRaccx\": \"gaussian_kde\",\n",
    "    \"Wrist_IQRaccy\": \"gaussian_kde\",\n",
    "    \"Wrist_IQRvelx\": \"gaussian_kde\",\n",
    "    \"Wrist_IQRvely\": \"gaussian_kde\",\n",
    "    \"Wrist_IQRx\": \"gaussian_kde\",\n",
    "    \"Wrist_IQRy\": \"gaussian_kde\",\n",
    "    \"Wrist_lrCorr_x\": \"beta\",\n",
    "    \"Wrist_meanent\": \"gaussian_kde\",\n",
    "    \"Wrist_medianvelx\": \"gaussian_kde\",\n",
    "    \"Wrist_medianvely\": \"gaussian_kde\",\n",
    "    \"Wrist_medianx\": \"gaussian_kde\",\n",
    "    \"Wrist_mediany\": \"gaussian_kde\",\n",
    "}\n",
    "\n",
    "category_risk_constraint = {\n",
    "    \"constraint_class\": \"FixedCombinations\",\n",
    "    \"constraint_parameters\": {\n",
    "        \"column_names\": [\"risk\", \"category\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "risk_0_condition = Condition(\n",
    "    num_rows=RISK_0_ROWS,\n",
    "    column_values={\"risk\": 0}\n",
    ")\n",
    "risk_1_condition = Condition(\n",
    "    num_rows=RISK_1_ROWS,\n",
    "    column_values={\"risk\": 1}\n",
    ")\n",
    "\n",
    "synth_train = GaussianCopulaSynthesizer(\n",
    "    metadata,\n",
    "    numerical_distributions=distro_train,\n",
    "    enforce_min_max_values=True,\n",
    ")\n",
    "synth_train.add_constraints(\n",
    "    constraints=[\n",
    "        category_risk_constraint\n",
    "    ]\n",
    ")\n",
    "\n",
    "synth_train.fit(df_train.to_pandas())\n",
    "synth_train._set_random_state(RAND_STATE)\n",
    "synth_data_train = synth_train.sample(num_rows=NUM_ROWS)\n",
    "df_synth_train =  pl.DataFrame(synth_data_train)\n",
    "\n",
    "synth_test = GaussianCopulaSynthesizer(\n",
    "    metadata,\n",
    "    numerical_distributions=distro_test,\n",
    "    enforce_min_max_values=True,\n",
    ")\n",
    "synth_test.add_constraints(\n",
    "    constraints=[\n",
    "        category_risk_constraint\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "synth_test.fit(df_test.to_pandas())\n",
    "synth_test._set_random_state(RAND_STATE)\n",
    "synth_data_test = synth_test.sample_from_conditions(\n",
    "    conditions=[risk_0_condition, risk_1_condition]\n",
    ")\n",
    "df_synth_test =  pl.DataFrame(synth_data_test)\n",
    "\n",
    "df_synth_train.write_ipc(IPC_DIR / \"synth_train.ipc\")\n",
    "df_synth_test.write_ipc(IPC_DIR / \"synth_test.ipc\")\n",
    "\n",
    "df_synth_train_long = df_synth_train.unpivot(on=FEATURES, index=[\"infant\", \"risk\", \"category\", \"age_bracket\"], variable_name=\"feature\", value_name=\"value\")\n",
    "df_synth_train_long.write_ipc(IPC_DIR / \"synth_train_long.ipc\")\n",
    "\n",
    "df_synth_test_long = df_synth_test.unpivot(on=FEATURES, index=[\"infant\", \"risk\", \"category\", \"age_bracket\"], variable_name=\"feature\", value_name=\"value\")\n",
    "df_synth_test_long.write_ipc(IPC_DIR / \"synth_test_long.ipc\")\n",
    "\n",
    "df_synth_long = df_synth_train_long.vstack(df_synth_test_long)\n",
    "df_synth_long.write_ipc(IPC_DIR / \"synth_long.ipc\")"
   ],
   "id": "e7d30b08f12a737b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Evaluate Synthetic Data",
   "id": "c2d47430978b7e0e"
  },
  {
   "cell_type": "markdown",
   "id": "doc-cell-3",
   "metadata": {},
   "source": [
    "### 5.3 Evaluate Synthetic Data Quality\n",
    "\n",
    "These cells use `sdv`'s evaluation utilities to assess the quality of the generated synthetic data. `run_diagnostic` checks for basic validity, while `evaluate_quality` provides a more detailed report comparing the statistical properties of the real and synthetic data. The `Column Shapes` visualization helps to visually confirm that the distributions of features are similar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "doc-cell-4",
   "metadata": {},
   "source": [
    "### 5.4 Manual Inspection of Risk Distributions\n",
    "\n",
    "The final set of cells performs manual checks on the `risk` distribution within the synthetic and real datasets. This provides a quick, hands-on verification that the synthesizers have reasonably preserved the prevalence of different risk categories."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "diagnostic = run_diagnostic(df_train.to_pandas(), pl.DataFrame(synth_data_train).to_pandas(), metadata)\n",
    "quality_report = evaluate_quality(df_train.to_pandas(), pl.DataFrame(synth_data_train).to_pandas(), metadata)\n",
    "quality_report.get_visualization(\"Column Shapes\")"
   ],
   "id": "ad250783a7029e13",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "diagnostic = run_diagnostic(df_test.to_pandas(), pl.DataFrame(synth_data_test).to_pandas(), metadata)\n",
    "quality_report = evaluate_quality(df_test.to_pandas(), pl.DataFrame(synth_data_test).to_pandas(), metadata)\n",
    "quality_report.get_visualization(\"Column Shapes\")"
   ],
   "id": "ad65337ef7d07e2e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# df_synth.group_by(\"risk\").len().with_columns(\n",
    "#     pct=pl.col(\"len\") / df_synth.height\n",
    "# )\n",
    "# 0: 862 | 86.2%\n",
    "# 1:  29 |  2.9%\n",
    "# 2:  64 |  6.4%\n",
    "# 3:  45 |  4.5%\n"
   ],
   "id": "99c2c4bda093bc52",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_test.group_by(\"risk\").len().with_columns(\n",
    "    pct=pl.col(\"len\") / df_test.height\n",
    ")\n",
    "# 0: 0 |  0.0%\n",
    "# 1: 5 | 26.3%\n",
    "# 2: 9 | 47.4%\n",
    "# 3: 5 | 26.3%"
   ],
   "id": "13ecf852c5b1b97c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_synth_test.group_by(\"risk\").len().with_columns(\n",
    "    pct=pl.col(\"len\") / df_synth_test.height\n",
    ")"
   ],
   "id": "f53d57b96bf3106",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "df_train.group_by(\"risk\").len().with_columns(\n",
    "    pct=pl.col(\"len\") / df_train.height\n",
    ")\n",
    "# 0: 124 | 100.0%\n",
    "# 1:   0 |   0.0%\n",
    "# 2:   0 |   0.0%\n",
    "# 3:   0 |   0.0%\n",
    "\n",
    "# 0 + 1 : 129 | 90.2%\n",
    "# 2 + 3 :  14 |  9.8%\n",
    "\n",
    "# 14 / 143 = 9.8%"
   ],
   "id": "8c0bdb521cee0384",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_synth_train.group_by(\"risk\").len().with_columns(\n",
    "    pct=pl.col(\"len\") / df_synth_train.height\n",
    ")"
   ],
   "id": "bb42030a9f942a8d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "dfe5f9c10c80d15b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# %reload_ext autoreload\n",
    "# %autoreload 2\n",
    "# \n",
    "# import polars as pl\n",
    "# from polars import DataFrame\n",
    "# from sdv.metadata import Metadata\n",
    "# from sdv.single_table import GaussianCopulaSynthesizer\n",
    "# from sdv.evaluation.single_table import run_diagnostic, evaluate_quality, get_column_plot\n",
    "# \n",
    "# from early_markers.cribsy.common.data import get_dataframes, get_merged_dataframe\n",
    "# from early_markers.cribsy.common.constants import JSON_DIR, IPC_DIR, RAND_STATE, FEATURES\n",
    "# \n",
    "# frames = get_dataframes()\n",
    "# \n",
    "# df_long_all = get_merged_dataframe().rename({\"Value\": \"value\"}).with_columns(\n",
    "#     feature=pl.concat_str(\"part\", \"feature_name\", separator=\"_\")\n",
    "# ).filter(pl.col(\"part\") != \"umber\")\n",
    "#       \n",
    "# df_wide_all: DataFrame = df_long_all.pivot(on=\"feature\", index=[\"infant\", \"risk_raw\", \"category\"], values=[\"value\"]).drop(\"Shoulder_lrCorr_x\")  # Shoulder_lrCorr_x is constant = 1\n",
    "# \n",
    "# df_train = df_wide_all.filter(pl.col(\"category\") == 0)\n",
    "# df_test = df_wide_all.filter(pl.col(\"category\") == 1)\n",
    "# \n",
    "# metadata = Metadata.detect_from_dataframe(\n",
    "#     data=df_wide_all.to_pandas(),\n",
    "#     table_name=\"features\",\n",
    "# )\n",
    "# metadata.update_column(\n",
    "#     column_name=\"risk_raw\",\n",
    "#     sdtype = \"categorical\"\n",
    "# )\n",
    "# metadata.save_to_json(JSON_DIR / \"sdv_metadata.json\", mode=\"overwrite\")\n",
    "# \n",
    "# distributions = {\n",
    "#     # \"risk_raw\": \"beta\",\n",
    "#     # \"category\": \"beta\",\n",
    "#     \"Ankle_IQRaccx\": \"gaussian_kde\",\n",
    "#     \"Ankle_IQRaccy\": \"gaussian_kde\",\n",
    "#     \"Ankle_IQRvelx\": \"gaussian_kde\",\n",
    "#     \"Ankle_IQRvely\": \"gaussian_kde\",\n",
    "#     \"Ankle_IQRx\": \"norm\",\n",
    "#     \"Ankle_IQRy\": \"beta\",\n",
    "#     \"Ankle_lrCorr_x\": \"beta\",\n",
    "#     \"Ankle_meanent\": \"gaussian_kde\",\n",
    "#     \"Ankle_medianvelx\": \"gaussian_kde\",\n",
    "#     \"Ankle_medianvely\": \"norm\",\n",
    "#     \"Ankle_medianx\": \"norm\",\n",
    "#     \"Ankle_mediany\": \"gaussian_kde\",\n",
    "#     \"Ear_lrCorr_x\": \"norm\",\n",
    "#     \"Elbow_IQR_acc_angle\": \"gaussian_kde\",\n",
    "#     \"Elbow_IQR_vel_angle\": \"gaussian_kde\",\n",
    "#     \"Elbow_entropy_angle\": \"beta\",\n",
    "#     \"Elbow_lrCorr_angle\": \"beta\",\n",
    "#     \"Elbow_lrCorr_x\": \"norm\",\n",
    "#     \"Elbow_mean_angle\": \"gaussian_kde\",\n",
    "#     \"Elbow_median_vel_angle\": \"gaussian_kde\",\n",
    "#     \"Elbow_stdev_angle\": \"norm\",\n",
    "#     \"Eye_lrCorr_x\": \"beta\",  # ***\n",
    "#     \"Hip_IQR_acc_angle\": \"gaussian_kde\",\n",
    "#     \"Hip_IQR_vel_angle\": \"gaussian_kde\",\n",
    "#     \"Hip_entropy_angle\": \"beta\",\n",
    "#     \"Hip_lrCorr_angle\": \"beta\",\n",
    "#     \"Hip_lrCorr_x\": \"gaussian_kde\",  # ***\n",
    "#     \"Hip_mean_angle\": \"gaussian_kde\",\n",
    "#     \"Hip_median_vel_angle\": \"gaussian_kde\",\n",
    "#     \"Hip_stdev_angle\": \"gaussian_kde\",\n",
    "#     \"Knee_IQR_acc_angle\": \"gaussian_kde\",\n",
    "#     \"Knee_IQR_vel_angle\": \"gaussian_kde\",\n",
    "#     \"Knee_entropy_angle\": \"gaussian_kde\",\n",
    "#     \"Knee_lrCorr_angle\": \"norm\",\n",
    "#     \"Knee_lrCorr_x\": \"gaussian_kde\",\n",
    "#     \"Knee_mean_angle\": \"gaussian_kde\",\n",
    "#     \"Knee_median_vel_angle\": \"gaussian_kde\",\n",
    "#     \"Knee_stdev_angle\": \"beta\",\n",
    "#     \"Shoulder_IQR_acc_angle\": \"gaussian_kde\",\n",
    "#     \"Shoulder_IQR_vel_angle\": \"gaussian_kde\",\n",
    "#     \"Shoulder_entropy_angle\": \"norm\",\n",
    "#     \"Shoulder_lrCorr_angle: \"norm\",\n",
    "#     # \"Shoulder_lrCorr_x\": \"beta\",\n",
    "#     \"Shoulder_mean_angle\": \"gaussian_kde\",\n",
    "#     \"Shoulder_median_vel_angle\": \"beta\",\n",
    "#     \"Shoulder_stdev_angle\": \"beta\",\n",
    "#     \"Wrist_IQRaccx\": \"gaussian_kde\",\n",
    "#     \"Wrist_IQRaccy\": \"gaussian_kde\",\n",
    "#     \"Wrist_IQRvelx\": \"gaussian_kde\",\n",
    "#     \"Wrist_IQRvely\": \"gaussian_kde\",\n",
    "#     \"Wrist_IQRx\": \"gaussian_kde\",\n",
    "#     \"Wrist_IQRy\": \"gaussian_kde\",\n",
    "#     \"Wrist_lrCorr_x\": \"beta\",\n",
    "#     \"Wrist_meanent\": \"gaussian_kde\",\n",
    "#     \"Wrist_medianvelx\": \"gaussian_kde\",\n",
    "#     \"Wrist_medianvely\": \"gaussian_kde\",\n",
    "#     \"Wrist_medianx\": \"norm\",\n",
    "#     \"Wrist_mediany\": \"gaussian_kde\",\n",
    "# }\n",
    "# \n",
    "# category_risk_constraint = {\n",
    "#     \"constraint_class\": \"FixedCombinations\",\n",
    "#     \"constraint_parameters\": {\n",
    "#         \"column_names\": [\"risk_raw\", \"category\"]\n",
    "#     }\n",
    "# }\n",
    "# \n",
    "# synthesizer = GaussianCopulaSynthesizer(\n",
    "#     metadata,\n",
    "#     numerical_distributions=distributions,\n",
    "#     enforce_min_max_values=True,\n",
    "# )\n",
    "# synthesizer.add_constraints(\n",
    "#     constraints=[\n",
    "#         category_risk_constraint\n",
    "#     ]\n",
    "# )\n",
    "# synthesizer.fit(df_wide_all.to_pandas())\n",
    "# synthesizer._set_random_state(RAND_STATE)\n",
    "# synthetic_data = synthesizer.sample(num_rows=1000)\n",
    "# df_synth =  pl.DataFrame(synthetic_data).with_columns(\n",
    "#     risk=pl.col(\"risk_raw\") >= 2\n",
    "# ).drop(\"risk_raw\")"
   ],
   "id": "45c855c262b601ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# import math\n",
    "# %reload_ext autoreload\n",
    "# %autoreload 2\n",
    "# \n",
    "# import polars as pl\n",
    "# from polars import DataFrame\n",
    "# import polars.selectors as cs\n",
    "# from sdv.metadata import Metadata\n",
    "# from sdv.single_table import GaussianCopulaSynthesizer\n",
    "# from sdv.evaluation.single_table import run_diagnostic, evaluate_quality, get_column_plot\n",
    "# \n",
    "# from early_markers.cribsy.common.data import get_dataframes, get_merged_dataframe\n",
    "# from early_markers.cribsy.common.constants import JSON_DIR, IPC_DIR, RAND_STATE, FEATURES\n",
    "# \n",
    "# frames = get_dataframes()\n",
    "# \n",
    "# df_long_all = get_merged_dataframe().rename({\"Value\": \"value\"}).with_columns(\n",
    "#     feature=pl.concat_str(\"part\", \"feature_name\", separator=\"_\")\n",
    "# ).filter(pl.col(\"part\") != \"umber\")\n",
    "#       \n",
    "# df_wide_all: DataFrame = df_long_all.pivot(on=\"feature\", index=[\"infant\", \"risk_raw\", \"category\"], values=[\"value\"]).drop([\"Shoulder_lrCorr_x\", \"Hip_lrCorr_x\"])  # Shoulder_lrCorr_x is constant = 1\n",
    "# \n",
    "# df_train = df_wide_all.filter(pl.col(\"category\") == 0).with_columns(\n",
    "#     risk=(pl.col(\"risk_raw\") >= 2).cast(pl.Int64)\n",
    "# ).select([\"infant\", \"category\", \"risk\", cs.exclude([\"infant\", \"category\", \"risk\"])]).drop(\"risk_raw\")\n",
    "# \n",
    "# df_test = df_wide_all.filter(pl.col(\"category\") == 1).with_columns(\n",
    "#     risk=(pl.col(\"risk_raw\") >= 2).cast(pl.Int64)\n",
    "# ).select([\"infant\", \"category\", \"risk\", cs.exclude([\"infant\", \"category\", \"risk\"])]).drop(\"risk_raw\")\n",
    "# \n",
    "# df_train\n",
    "\n",
    "# PEB 2025.03.26 22:28 => Need to create and validate a model based only on kiddos age >= 10 weeks\n",
    "# Will need to ensure both train and test synth datasets are 90/10 no-risk/risk\n"
   ],
   "id": "6748caade195eef8",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
