{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "doc-main-summary",
   "metadata": {},
   "source": [
    "# 08 - Bayesian and Frequentist Sample Size Calculation\n",
    "\n",
    "**Purpose**: This notebook provides a set of functions for calculating the required sample size for both model development and performance evaluation, offering both Bayesian and frequentist approaches.\n",
    "\n",
    "**Inputs**:\n",
    "- Pilot study data (for model development).\n",
    "- Expected performance metrics (sensitivity, specificity, prevalence) for performance evaluation.\n",
    "\n",
    "**Outputs**:\n",
    "- The notebook prints the calculated sample sizes for model development and performance evaluation based on the example usage.\n",
    "\n",
    "### Key Functions:\n",
    "1.  **`beta_hdi()`**: Calculates the Highest Density Interval (HDI) for a Beta distribution.\n",
    "2.  **`model_development_sample_size()`**: A Bayesian simulation to determine the sample size needed for stable model parameter estimation.\n",
    "3.  **`performance_sample_size()`**: Calculates the sample size needed to estimate classification performance metrics (sensitivity and specificity) to a desired precision. This function can use either a frequentist (Buderer's formula) or a Bayesian simulation approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "doc-cell-1",
   "metadata": {},
   "source": [
    "### 8.1 Sample Size Calculation Functions and Examples\n",
    "\n",
    "This cell defines and demonstrates the functions for sample size calculation.\n",
    "\n",
    "- **`beta_hdi`**: A helper function to find the optimal Highest Density Interval for a Beta distribution.\n",
    "- **`model_development_sample_size`**: Implements a Bayesian simulation to find the sample size needed to ensure the model's parameter estimates are stable (i.e., have a narrow HDI). It uses a Beta-Binomial model and iterates through sample sizes until a target assurance level is met.\n",
    "- **`performance_sample_size`**: A versatile function that calculates the required sample size to evaluate classification performance. It supports both a frequentist method (using Buderer's formula) and a Bayesian simulation method.\n",
    "- **Example Usage**: The final part of the cell demonstrates how to use these functions with sample pilot data and performance targets, printing the estimated required sample sizes for both model development and performance evaluation."
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from importlib import reload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from scipy.optimize import fmin\n",
    "\n",
    "def beta_hdi(alpha, beta, ci=0.95):\n",
    "    \"\"\"Calculate HDI for Beta distribution using optimization.\n",
    "\n",
    "    Args:\n",
    "        alpha (float): The alpha parameter of the Beta distribution.\n",
    "        beta (float): The beta parameter of the Beta distribution.\n",
    "        ci (float, optional): The desired credible interval coverage. Defaults to 0.95.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the lower and upper bounds of the HDI.\n",
    "    \"\"\"",
    "    def interval_width(low):\n",
    "        high = low + ci\n",
    "        lower = stats.beta.ppf(low, alpha, beta)\n",
    "        upper = stats.beta.ppf(high, alpha, beta)\n",
    "        return abs(upper - lower)\n",
    "    \n",
    "    result = fmin(interval_width, (1 - ci)/2, disp=False)\n",
    "    low = result[0]\n",
    "    high = low + ci\n",
    "    return stats.beta.ppf([low, high], alpha, beta)\n",
    "\n",
    "# --------------------------\n",
    "# 1. Model Development Sample Size (Beta-Binomial)\n",
    "# --------------------------\n",
    "\n",
    "def model_development_sample_size(pilot_data, hdi_width=0.2, ci=0.95, \n",
    "                                  min_n=10, max_n=1000, step=10, \n",
    "                                  simulations=1000, target_prob=0.8):\n",
    "    \"\"\"Determine sample size for stable model parameters using Bayesian simulation.\n",
    "\n",
    "    This function simulates future data collection to find the sample size `n` at\n",
    "    which there is a high probability (`target_prob`) that the resulting\n",
    "    posterior distribution's HDI will be narrower than `hdi_width`.\n",
    "\n",
    "    Args:\n",
    "        pilot_data (np.array): A binary array (1s/0s) of data from a pilot study.\n",
    "        hdi_width (float, optional): The desired HDI width threshold. Defaults to 0.2.\n",
    "        ci (float, optional): The credible interval level. Defaults to 0.95.\n",
    "        min_n (int, optional): The minimum sample size to test. Defaults to 10.\n",
    "        max_n (int, optional): The maximum sample size to test. Defaults to 1000.\n",
    "        step (int, optional): The increment for searching sample sizes. Defaults to 10.\n",
    "        simulations (int, optional): The number of simulations to run per sample size. Defaults to 1000.\n",
    "        target_prob (float, optional): The desired probability of achieving the HDI width. Defaults to 0.8.\n",
    "\n",
    "    Returns:\n",
    "        int | None: The optimal sample size, or None if not found within the search range.\n",
    "    \"\"\"",
    "    # Convert pilot data to Beta prior\n",
    "    successes = np.sum(pilot_data)\n",
    "    failures = len(pilot_data) - successes\n",
    "    alpha_prior = successes + 1\n",
    "    beta_prior = failures + 1\n",
    "    p_pilot = np.mean(pilot_data)\n",
    "    \n",
    "    # Search through candidate sample sizes\n",
    "    for n in range(min_n, max_n+1, step):\n",
    "        valid_count = 0\n",
    "        \n",
    "        for _ in range(simulations):\n",
    "            # Generate synthetic data\n",
    "            k = np.random.binomial(n, p_pilot)\n",
    "            \n",
    "            # Calculate posterior parameters\n",
    "            alpha_post = alpha_prior + k\n",
    "            beta_post = beta_prior + (n - k)\n",
    "            \n",
    "            # Calculate HDI width\n",
    "            lower, upper = beta_hdi(alpha_post, beta_post, ci)\n",
    "            width = upper - lower\n",
    "            \n",
    "            if width <= hdi_width:\n",
    "                valid_count += 1\n",
    "                \n",
    "        probability = valid_count / simulations\n",
    "        if probability >= target_prob:\n",
    "            return n\n",
    "        \n",
    "    return None\n",
    "\n",
    "# --------------------------\n",
    "# 2. Performance Evaluation Sample Size\n",
    "# --------------------------\n",
    "\n",
    "def performance_sample_size(sens=0.8, spec=0.85, prevalence=0.3, \n",
    "                            hdi_width=0.1, ci=0.95, method='bayesian',\n",
    "                            prior_strength=10, simulations=1000):\n",
    "    \"\"\"Calculate sample size for classification performance estimation.\n",
    "\n",
    "    This function can operate in two modes:\n",
    "    - 'frequentist': Uses Buderer's formula for a quick, analytical estimate.\n",
    "    - 'bayesian': Uses a simulation-based approach to find the sample size\n",
    "      that achieves a desired HDI width with a certain probability (assurance).\n",
    "\n",
    "    Args:\n",
    "        sens (float, optional): Expected sensitivity. Defaults to 0.8.\n",
    "        spec (float, optional): Expected specificity. Defaults to 0.85.\n",
    "        prevalence (float, optional): Expected prevalence of the condition. Defaults to 0.3.\n",
    "        hdi_width (float, optional): Desired HDI width. Defaults to 0.1.\n",
    "        ci (float, optional): Credible/confidence interval level. Defaults to 0.95.\n",
    "        method (str, optional): 'bayesian' or 'frequentist'. Defaults to 'bayesian'.\n",
    "        prior_strength (int, optional): Strength of the Beta prior for the Bayesian method. Defaults to 10.\n",
    "        simulations (int, optional): Number of simulations for the Bayesian method. Defaults to 1000.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the estimated total sample size and a dictionary\n",
    "            with the breakdown of required cases for sensitivity and specificity.\n",
    "    \"\"\"",
    "    \n",
    "    if method == 'frequentist':\n",
    "        # Buderer's formula implementation [4]\n",
    "        z = stats.norm.ppf(1 - (1 - ci)/2)\n",
    "        \n",
    "        # Sensitivity calculation\n",
    "        n_sens = (z**2 * sens * (1 - sens)) / (hdi_width/2)**2 \n",
    "        n_sens /= prevalence\n",
    "        \n",
    "        # Specificity calculation\n",
    "        n_spec = (z**2 * spec * (1 - spec)) / (hdi_width/2)**2\n",
    "        n_spec /= (1 - prevalence)\n",
    "        \n",
    "        n_total = int(np.ceil(max(n_sens, n_spec)))\n",
    "        \n",
    "        return n_total, {\n",
    "            'sensitivity_sample': int(np.ceil(n_sens)),\n",
    "            'specificity_sample': int(np.ceil(n_spec))\n",
    "        }\n",
    "    \n",
    "    elif method == 'bayesian':\n",
    "        # Bayesian simulation approach\n",
    "        def find_sample_size(true_p, prev, is_sens=True):\n",
    "            alpha_prior = prior_strength * true_p + 1\n",
    "            beta_prior = prior_strength * (1 - true_p) + 1\n",
    "            \n",
    "            for n in range(10, 10000, 10):\n",
    "                valid = 0\n",
    "                cases = int(n * prev) if is_sens else int(n * (1 - prev))\n",
    "                if cases < 1: continue\n",
    "                \n",
    "                for _ in range(simulations):\n",
    "                    k = np.random.binomial(cases, true_p)\n",
    "                    alpha_post = alpha_prior + k\n",
    "                    beta_post = beta_prior + (cases - k)\n",
    "                    \n",
    "                    lower, upper = beta_hdi(alpha_post, beta_post, ci)\n",
    "                    if (upper - lower) <= hdi_width:\n",
    "                        valid += 1\n",
    "                \n",
    "                if valid/simulations >= 0.8:\n",
    "                    return n, cases\n",
    "            return None, None\n",
    "        \n",
    "        # Sensitivity calculation\n",
    "        n_sens_total, n_sens_cases = find_sample_size(sens, prevalence, True)\n",
    "        n_spec_total, n_spec_cases = find_sample_size(spec, prevalence, False)\n",
    "        \n",
    "        n_total = max(n_sens_total, n_spec_total)\n",
    "        \n",
    "        return n_total, {\n",
    "            'sensitivity': {\n",
    "                'total_samples': n_sens_total,\n",
    "                'positive_cases': n_sens_cases\n",
    "            },\n",
    "            'specificity': {\n",
    "                'total_samples': n_spec_total,\n",
    "                'negative_cases': n_spec_cases\n",
    "            }\n",
    "        }\n",
    "\n",
    "# --------------------------\n",
    "# Example Usage\n",
    "# --------------------------\n",
    "# Generate example pilot data (75% accuracy)\n",
    "np.random.seed(42)\n",
    "pilot_data = np.random.binomial(1, 0.75, 50)\n",
    "\n",
    "# 1. Model development sample size\n",
    "dev_sample_size = model_development_sample_size(\n",
    "    pilot_data, hdi_width=0.15, min_n=100, max_n=500\n",
    ")\n",
    "print(f\"Model development sample size: {dev_sample_size}\")\n",
    "\n",
    "# 2. Performance evaluation sample size\n",
    "# Frequentist approach\n",
    "n_freq, breakdown_freq = performance_sample_size(method='frequentist')\n",
    "print(f\"Frequentist sample size: {n_freq}\")\n",
    "print(breakdown_freq)\n",
    "\n",
    "# Bayesian approach\n",
    "n_bayes, breakdown_bayes = performance_sample_size(method='bayesian')\n",
    "print(f\"Bayesian sample size: {n_bayes}\")\n",
    "print(breakdown_bayes)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "doc-cell-2",
   "metadata": {},
   "source": [
    "### 8.2 Alternative BAM Implementation\n",
    "\n",
    "This cell defines `bam_n_dev`, an alternative implementation of the Bayesian Assurance Method logic for model development when planning new studies. It uses a hierarchical prior and a binary search algorithm to find the optimal sample size, which can be more efficient than a linear search."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from scipy.optimize import fmin\n",
    "\n",
    "\n",
    "def bam_n_dev(pilot_data, hdi_width=0.1, ci=0.95, \n",
    "                             simulations=1000, target_assurance=0.8):\n",
    "    \"\"\"\n",
    "    BAM implementation for model development sample size\n",
    "    \"\"\"\n",
    "    # Hierarchical prior for pilot data\n",
    "    alpha_hyper = stats.gamma(a=2, scale=1).rvs()\n",
    "    beta_hyper = stats.gamma(a=2, scale=1).rvs()\n",
    "    alpha_post = alpha_hyper + np.sum(pilot_data)\n",
    "    beta_post = beta_hyper + len(pilot_data) - np.sum(pilot_data)\n",
    "    \n",
    "    # Binary search for optimal n\n",
    "    low, high = 10, 10000\n",
    "    while low <= high:\n",
    "        mid = (low + high) // 2\n",
    "        assurance = 0\n",
    "        \n",
    "        for _ in range(simulations):\n",
    "            theta = stats.beta(alpha_post, beta_post).rvs()\n",
    "            y_sim = stats.bernoulli(theta).rvs(mid)\n",
    "            alpha_post_sim = alpha_post + np.sum(y_sim)\n",
    "            beta_post_sim = beta_post + mid - np.sum(y_sim)\n",
    "            \n",
    "            lower, upper = beta_hdi(alpha_post_sim, beta_post_sim, ci)\n",
    "            if (upper - lower) <= hdi_width:\n",
    "                assurance += 1\n",
    "                \n",
    "        assurance_prob = assurance / simulations\n",
    "        if assurance_prob >= target_assurance:\n",
    "            high = mid - 1\n",
    "        else:\n",
    "            low = mid + 1\n",
    "            \n",
    "    return low\n"
   ],
   "id": "411ec46725652755",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
