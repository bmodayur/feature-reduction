{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "doc-main-summary",
   "metadata": {},
   "source": [
    "# 10 - Advanced Sample Size and Cluster Analysis\n",
    "\n",
    "**Purpose**: This notebook performs a detailed sample size analysis, extending the calculations to account for clustered data. It calculates the required number of individual subjects () and the required number of clusters () to achieve a desired precision for sensitivity and specificity.\n",
    "\n",
    "**Inputs**:\n",
    "- Pre-computed threshold data from , which contains sensitivity and specificity values at various Z-score thresholds.\n",
    "\n",
    "**Outputs**:\n",
    "- : A comprehensive Excel workbook with multiple sheets detailing:\n",
    "    - Sensitivity and Specificity at different Z-Thresholds.\n",
    "    - Required sample size (N) for different CI half-widths.\n",
    "    - Required number of clusters (K) for different ICC values and mean subjects per cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "doc-cell-1",
   "metadata": {},
   "source": [
    "### 10.1 Setup, Calculation Functions, and Data Generation\n",
    "\n",
    "This cell contains the complete logic for the sample size and cluster analysis...\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "import math\n",
    "from scipy.stats import norm\n",
    "\n",
    "\n",
    "from polars import DataFrame\n",
    "import polars as pl\n",
    "from xlsxwriter import Workbook\n",
    "\n",
    "from early_markers.cribsy.common.thresholds import (\n",
    "    thresh_emcp,\n",
    "    thresh_emcp_yt,\n",
    "    thresh_yt,\n",
    ")\n",
    "\n",
    "\n",
    "ROOT_DIR = Path(\"/Volumes/secure/data/early_markers/cribsy\")\n",
    "XLSX_DIR = ROOT_DIR / \"xlsx\"\n",
    "\n",
    "# TEST_PCT = 0.25\n",
    "# METRIC_RANGE = [0.75, 0.8, 0.85, 0.9, 1.0]\n",
    "HW_RANGE = [0.025, 0.05, 0.075, 0.10, 0.125, 0.15, 0.175, 0.20, 0.225]\n",
    "THRESH_RANGE = [-1.6, -1.4, -1.2, -1.0, -0.8, -0.6, -0.4]\n",
    "ICC_RANGE = [0.8, 0.85, 0.9, 0.95, 0.99]\n",
    "CLUSTER_RANGE = [1.0, 1.25, 1.5, 1.75, 2.0]\n",
    "\n",
    "THRESH_MAP = {\n",
    "    \"emcp\": thresh_emcp,\n",
    "    \"yt\": thresh_yt,\n",
    "    \"emcp_yt\": thresh_emcp_yt,\n",
    "}\n",
    "\n",
    "LABEL_MAP = {\n",
    "    \"emcp\": \"EMCP\",\n",
    "    \"yt\": \"Youtube\",\n",
    "    \"emcp_yt\": \"EMCP & Youtube\",\n",
    "    \"sensitivity\": \"Sensitivity\",\n",
    "    \"specificity\": \"Specificity\",\n",
    "}\n",
    "\n",
    "COL_MAP_THRESH = {\n",
    "    \"threshold\": \"Z-Threshold\",\n",
    "    \"sensitivity\": \"Sensitivity\",\n",
    "    \"sens_ci\": \"Se 95% CI\",\n",
    "    # \"sens_ci_lb\": \"Se 95% CI LB\",\n",
    "    # \"sens_ci_ub\": \"Se 95% CI UB\",\n",
    "    \"sens_ci_half_width\": \"Se ½-Width\",\n",
    "    \"specificity\": \"Specificity\",\n",
    "    \"spec_ci\": \"Sp 95% CI\",\n",
    "    # \"spec_ci_lb\": \"Sp 95% CI LB\",\n",
    "    # \"spec_ci_ub\": \"Sp 95% CI UB\",\n",
    "    \"spec_ci_half_width\": \"Sp ½-Width\",\n",
    "}\n",
    "#\n",
    "# COL_MAP_SENS = {\n",
    "#     \"sensitivity\": \"Sensitivity\",\n",
    "#     \"sens_ci_lb\": \"Se 95% CI LB\",\n",
    "#     \"sens_ci_ub\": \"Se 95% CI UB\",\n",
    "#     \"sens_ci_half_width\": \"Se 95% CI ½-Width\",\n",
    "#     \"n\": \"N\",\n",
    "# }\n",
    "#\n",
    "# COL_MAP_SPEC = {\n",
    "#     \"specificity\": \"Specificity\",\n",
    "#     \"spec_ci_lb\": \"Sp 95% CI LB\",\n",
    "#     \"spec_ci_ub\": \"Sp 95% CI UB\",\n",
    "#     \"spec_ci_half_width\": \"Sp 95% CI ½-Width\",\n",
    "#     \"n\": \"N\",\n",
    "# }\n",
    "\n",
    "COL_MAP_SAMPLE_SIZE = {\n",
    "    'threshold': \"Z-Threshold\",\n",
    "    'half_width': \"95% CI Half_Width\",\n",
    "    'sensitivity': \"Sensitivity\",\n",
    "    \"sens_ci\": \"Se 95% CI\",\n",
    "    'specificity': \"Specificity\",\n",
    "    \"spec_ci\": \"Sp 95% CI\",\n",
    "    'n_sens': \"N Sensitivity\",\n",
    "    'n_spec': \"N Specificity\",\n",
    "    'n_train': \"N Train\",\n",
    "    'n_test': \"N Test\",\n",
    "    'n_study': \"N Study\",\n",
    "}\n",
    "\n",
    "COL_MAP_CLUSTER_SIZE = {\n",
    "    'threshold': \"Z-Threshold\",\n",
    "    'half_width': \"95% CI Half_Width\",\n",
    "    \"mean_n_per_k\": \"Mean N per K\",\n",
    "    \"icc\": \"ICC\",\n",
    "    'sensitivity': \"Sensitivity\",\n",
    "    \"sens_ci\": \"Se 95% CI\",\n",
    "    'specificity': \"Specificity\",\n",
    "    \"spec_ci\": \"Sp 95% CI\",\n",
    "    'k_sens': \"K Sensitivity\",\n",
    "    'k_spec': \"K Specificity\",\n",
    "    'k_train': \"K Train\",\n",
    "    'k_test': \"K Test\",\n",
    "    'k_study': \"K Study\",\n",
    "}\n",
    "\n",
    "DF_THRESH_MAP = {\n",
    "    label: DataFrame(thresh).with_columns(\n",
    "        sens_ci_lb_width = pl.col(\"sensitivity\") - pl.col(\"sens_ci_lb\"),\n",
    "        sens_ci_ub_width = pl.col(\"sens_ci_ub\") - pl.col(\"sensitivity\"),\n",
    "        spec_ci_lb_width = pl.col(\"specificity\") - pl.col(\"spec_ci_lb\"),\n",
    "        spec_ci_ub_width = pl.col(\"spec_ci_ub\") - pl.col(\"specificity\"),\n",
    "\n",
    "    ).with_columns(\n",
    "        sens_ci_half_width = pl.max_horizontal(pl.col(\"sens_ci_lb_width\"), pl.col(\"sens_ci_ub_width\")),\n",
    "        spec_ci_half_width = pl.max_horizontal(pl.col(\"spec_ci_lb_width\"), pl.col(\"spec_ci_ub_width\")),\n",
    "    ).select(\n",
    "        [\"threshold\", \"sensitivity\", \"sens_ci\", \"sens_ci_half_width\", \"specificity\", \"spec_ci\", \"spec_ci_half_width\"]\n",
    "    )\n",
    "    for label, thresh in THRESH_MAP.items()\n",
    "}\n",
    "\n",
    "\n",
    "def n_for_proportion(proportion: float, half_width: float, confidence_level: float) -> int:\n",
    "    # Z-score for 95% confidence level\n",
    "    alpha = 1 - confidence_level\n",
    "    z = norm.ppf(1 - alpha / 2)\n",
    "    # Estimated proportion and its complement\n",
    "    p = proportion\n",
    "    q = 1 - p\n",
    "    # Formula to calculate sample size\n",
    "    n = (z**2 * p * q) / (half_width**2)\n",
    "    # Return the ceiling of the calculated sample size\n",
    "    return math.ceil(n)\n",
    "\n",
    "def k_for_proportion(proportion: float, half_width: float, confidence_level: float, icc: float, mean_n_per_k: float):\n",
    "    # Z-score for 95% confidence level\n",
    "    alpha = 1 - confidence_level\n",
    "    z = norm.ppf(1 - alpha / 2)\n",
    "    # Estimated proportion and its complement\n",
    "    p = proportion\n",
    "    q = 1 - p\n",
    "    # Variance of sensitivity\n",
    "    variance = p * q\n",
    "    # Design effect for clustering\n",
    "    design_effect = 1 + (mean_n_per_k - 1) * icc\n",
    "    # Adjusted variance for clustering\n",
    "    adjusted_variance = variance * design_effect\n",
    "    # Formula to calculate number of clusters\n",
    "    num_clusters = (z**2 * adjusted_variance) / (half_width**2)\n",
    "    # Return the ceiling of the calculated number of clusters\n",
    "    return math.ceil(num_clusters)\n",
    "\n",
    "SAMPLE_MAP = {}\n",
    "for model, df_thresh in DF_THRESH_MAP.items():\n",
    "    SAMPLE_MAP[model] = {}\n",
    "    for metric in [\"sensitivity\", \"specificity\"]:\n",
    "        SAMPLE_MAP[model][metric] = map = []\n",
    "        for thresh in THRESH_RANGE:\n",
    "            for half_width in HW_RANGE:\n",
    "                val = df_thresh.filter(pl.col(\"threshold\") == thresh).select(metric).item()\n",
    "                train = n_for_proportion(val, half_width, 0.95)\n",
    "                test = train\n",
    "                study = train + test\n",
    "                map.append(\n",
    "                    {\n",
    "                        \"model\": model,\n",
    "                        \"metric\": metric,\n",
    "                        \"z\": thresh,\n",
    "                        \"estimate\": val,\n",
    "                        \"half_width\": half_width,\n",
    "                        \"lb\": max(0.0, val - half_width),\n",
    "                        \"ub\": min(1.0, val + half_width),\n",
    "                        \"n_train\": train,\n",
    "                        \"n_test\": test,\n",
    "                        \"n_study\": study,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "DF_METRIC_SAMPLE_MAP = {\n",
    "    f\"{model}_{metric}\": DataFrame(rows)\n",
    "    for model, metric_map in SAMPLE_MAP.items()\n",
    "    for metric, rows in metric_map.items()\n",
    "}\n",
    "\n",
    "DF_SAMPLE_SIZE_MAP = {}\n",
    "for model in THRESH_MAP.keys():\n",
    "    data = []\n",
    "    for z in THRESH_RANGE:\n",
    "        for half_width in HW_RANGE:\n",
    "            df_sens = DF_METRIC_SAMPLE_MAP[f\"{model}_sensitivity\"].filter(pl.col(\"z\") == z, pl.col(\"half_width\") == half_width).select([\"z\", \"estimate\", \"lb\", \"ub\", \"n_train\", \"n_test\", \"n_study\"])\n",
    "            df_spec = DF_METRIC_SAMPLE_MAP[f\"{model}_specificity\"].filter(pl.col(\"z\") == z, pl.col(\"half_width\") == half_width).select([\"z\", \"estimate\", \"lb\", \"ub\", \"n_train\", \"n_test\", \"n_study\"])\n",
    "            train = max(df_sens.select(\"n_train\").item(), df_spec.select(\"n_train\").item())\n",
    "            test = train\n",
    "            study = train + test\n",
    "            data.append(\n",
    "                {\n",
    "                    \"threshold\": z,\n",
    "                    \"half_width\": half_width,\n",
    "                    \"sensitivity\": df_sens.select(\"estimate\").item(),\n",
    "                    \"sens_ci\": f\"[{df_sens.select(\"lb\").item():.3f}, {df_sens.select(\"ub\").item():.3f}]\",\n",
    "                    \"specificity\": df_spec.select(\"estimate\").item(),\n",
    "                    \"spec_ci\": f\"[{df_spec.select(\"lb\").item():.3f}, {df_spec.select(\"ub\").item():.3f}]\",\n",
    "                    \"n_sens\": df_sens.select(\"n_train\").item(),\n",
    "                    \"n_spec\": df_spec.select(\"n_train\").item(),\n",
    "                    \"n_train\": train,\n",
    "                    \"n_test\": test,\n",
    "                    \"n_study\": study,\n",
    "                }\n",
    "            )\n",
    "    DF_SAMPLE_SIZE_MAP[model] = DataFrame(data).sort(\"threshold\", \"half_width\", descending=[True, False]).rename(COL_MAP_SAMPLE_SIZE)\n",
    "\n",
    "CLUSTER_MAP = {}\n",
    "for model, df_thresh in DF_THRESH_MAP.items():\n",
    "    CLUSTER_MAP[model] = {}\n",
    "    for metric in [\"sensitivity\", \"specificity\"]:\n",
    "        CLUSTER_MAP[model][metric] = map = []\n",
    "        for thresh in THRESH_RANGE:\n",
    "            for half_width in HW_RANGE:\n",
    "                for cluster in CLUSTER_RANGE:\n",
    "                    for icc in ICC_RANGE:\n",
    "                        val = df_thresh.filter(pl.col(\"threshold\") == thresh).select(metric).item()\n",
    "                        train = k_for_proportion(val, half_width, 0.95, icc, cluster)\n",
    "                        test = train\n",
    "                        study = train + test\n",
    "                        map.append(\n",
    "                            {\n",
    "                                \"model\": model,\n",
    "                                \"metric\": metric,\n",
    "                                \"z\": thresh,\n",
    "                                \"mean_n_per_k\": cluster,\n",
    "                                \"icc\": icc,\n",
    "                                \"estimate\": val,\n",
    "                                \"half_width\": half_width,\n",
    "                                \"lb\": max(0.0, val - half_width),\n",
    "                                \"ub\": min(1.0, val + half_width),\n",
    "                                \"k_train\": train,\n",
    "                                \"k_test\": test,\n",
    "                                \"k_study\": study,\n",
    "                            }\n",
    "                        )\n",
    "\n",
    "DF_METRIC_CLUSTER_MAP = {\n",
    "    f\"{model}_{metric}\": DataFrame(rows)\n",
    "    for model, metric_map in CLUSTER_MAP.items()\n",
    "    for metric, rows in metric_map.items()\n",
    "}\n",
    "\n",
    "DF_CLUSTER_SIZE_MAP = {}\n",
    "for model in THRESH_MAP.keys():\n",
    "    data = []\n",
    "    for z in THRESH_RANGE:\n",
    "        for mean_n_per_k in CLUSTER_RANGE:\n",
    "            for icc in ICC_RANGE:\n",
    "                for half_width in HW_RANGE:\n",
    "                    df_sens = DF_METRIC_CLUSTER_MAP[f\"{model}_sensitivity\"].filter(pl.col(\"z\") == z, pl.col(\"mean_n_per_k\") == mean_n_per_k, pl.col(\"icc\") == icc, pl.col(\"half_width\") == half_width).select([\"z\", \"mean_n_per_k\", \"icc\", \"estimate\", \"lb\", \"ub\", \"k_train\", \"k_test\", \"k_study\"])\n",
    "                    df_spec = DF_METRIC_CLUSTER_MAP[f\"{model}_specificity\"].filter(pl.col(\"z\") == z, pl.col(\"mean_n_per_k\") == mean_n_per_k, pl.col(\"icc\") == icc, pl.col(\"half_width\") == half_width).select([\"z\", \"mean_n_per_k\", \"icc\", \"estimate\", \"lb\", \"ub\", \"k_train\", \"k_test\", \"k_study\"])\n",
    "                    train = max(df_sens.select(\"k_train\").item(), df_spec.select(\"k_train\").item())\n",
    "                    test = train\n",
    "                    study = train + test\n",
    "                    data.append(\n",
    "                        {\n",
    "                            \"threshold\": z,\n",
    "                            \"mean_n_per_k\": df_sens.select(\"mean_n_per_k\").item(),\n",
    "                            \"icc\": df_sens.select(\"icc\").item(),\n",
    "                            \"half_width\": half_width,\n",
    "                            \"sensitivity\": df_sens.select(\"estimate\").item(),\n",
    "                            \"sens_ci\": f\"[{df_sens.select(\"lb\").item():.3f}, {df_sens.select(\"ub\").item():.3f}]\",\n",
    "                            \"specificity\": df_spec.select(\"estimate\").item(),\n",
    "                            \"spec_ci\": f\"[{df_spec.select(\"lb\").item():.3f}, {df_spec.select(\"ub\").item():.3f}]\",\n",
    "                            \"k_sens\": df_sens.select(\"k_train\").item(),\n",
    "                            \"k_spec\": df_spec.select(\"k_train\").item(),\n",
    "                            \"k_train\": train,\n",
    "                            \"k_test\": test,\n",
    "                            \"k_study\": study,\n",
    "                        }\n",
    "                    )\n",
    "    DF_CLUSTER_SIZE_MAP[model] = DataFrame(data).sort(\"threshold\", \"mean_n_per_k\", \"icc\", \"half_width\", descending=[True, False, False, False]).rename(COL_MAP_CLUSTER_SIZE)\n",
    "\n",
    "\n",
    "def set_workbook_formats(wb: Workbook) -> dict:\n",
    "    DK_BLUE = \"#4F81BD\"\n",
    "    MD_BLUE = \"#95B3D7\"\n",
    "    LT_BLUE = \"#DCE6F1\"\n",
    "\n",
    "    bold_fmt = wb.add_format({\"bold\": True})\n",
    "\n",
    "    head_fmt = wb.add_format({\"bold\": True, \"font_size\": 13})\n",
    "    head_fmt.set_align(\"left\")\n",
    "\n",
    "    hdr_fmt = wb.add_format({\"bold\": True, \"font_color\": \"white\"})\n",
    "    hdr_fmt.set_align(\"center\")\n",
    "    hdr_fmt.set_bg_color(DK_BLUE)\n",
    "\n",
    "    code_fmt = wb.add_format({\"bold\": True})\n",
    "    code_fmt.set_bg_color(MD_BLUE)\n",
    "\n",
    "    desc_fmt = wb.add_format()\n",
    "    desc_fmt.set_bg_color(LT_BLUE)\n",
    "\n",
    "    pct_fmt = wb.add_format({\"num_format\": \"0.00%\"})\n",
    "    blue_pct_fmt = wb.add_format({\"num_format\": \"0.00%\"})\n",
    "    blue_pct_fmt.set_bg_color(LT_BLUE)\n",
    "\n",
    "    return {\"bold\": bold_fmt, \"heading\": head_fmt, \"header\": hdr_fmt, \"code\": code_fmt, \"desc\": desc_fmt, \"pct\": pct_fmt, \"blue_pct\": blue_pct_fmt}\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "doc-cell-2",
   "metadata": {},
   "source": [
    "### 10.2 Generate Excel Report\n",
    "\n",
    "This final cell takes all the generated DataFrames and writes them into a multi-sheet Excel workbook...\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "wb = Workbook(XLSX_DIR / \"cribsy_sample_size.xlsx\")\n",
    "formats = set_workbook_formats(wb)\n",
    "\n",
    "ws = wb.add_worksheet(\"Z-Thresholds\")\n",
    "row = 0\n",
    "col = 0\n",
    "for key, df in DF_THRESH_MAP.items():\n",
    "    ws.merge_range(row, col, row, col+4, f\"Sensitivity & Specificity With 95% CI for {LABEL_MAP[key]}\", formats[\"heading\"])\n",
    "    row += 1\n",
    "    df.rename(COL_MAP_THRESH).write_excel(\n",
    "        wb, ws, position=(row, col),\n",
    "        table_style=\"Table Style Medium 9\",\n",
    "        autofit=True,\n",
    "        column_formats={\n",
    "            \"Z-Threshold\": {\"bold\": True},\n",
    "            \"Sensitivity\": {\"bold\": True},\n",
    "            \"Specificity\": {\"bold\": True},\n",
    "        },\n",
    "        conditional_formats={\n",
    "            (\"Sensitivity\", \"Specificity\"): {\n",
    "                \"type\": \"3_color_scale\"\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    row = row + df.height + 3\n",
    "\n",
    "ws.set_column(0, 6, 15)\n",
    "\n",
    "for model, df in DF_SAMPLE_SIZE_MAP.items():\n",
    "    ws = wb.add_worksheet(f\"N - {LABEL_MAP[model]}\")\n",
    "    row = 0\n",
    "    col = 0\n",
    "    ws.merge_range(row, col, row, col+4, f\"Sample Size Estimates by Z-Threshold and 95% CI Half-Width [{LABEL_MAP[model]}]\", formats[\"heading\"])\n",
    "    row += 1\n",
    "    df.write_excel(\n",
    "        wb, ws, position=(row, col),\n",
    "        table_style=\"Table Style Medium 9\",\n",
    "        autofit=True,\n",
    "        column_formats={\n",
    "            \"Z-Threshold\": {\"bold\": True},\n",
    "            \"Sensitivity\": {\"bold\": True},\n",
    "            \"Specificity\": {\"bold\": True},\n",
    "            \"N Study\": {\"bold\": True},\n",
    "        },\n",
    "        conditional_formats={\n",
    "            (\"Sensitivity\", \"Specificity\"): {\n",
    "                \"type\": \"3_color_scale\"\n",
    "            },\n",
    "            \"N Study\": {\n",
    "                \"type\": \"3_color_scale\",\n",
    "                \"max_color\": \"#f8696b\",\n",
    "                \"mid_color\": \"#ffeb83\",\n",
    "                \"min_color\": \"#63be7b\",\n",
    "            }\n",
    "        },\n",
    "    )\n",
    "    ws.set_column(0, 0, 15)\n",
    "\n",
    "for model, df in DF_CLUSTER_SIZE_MAP.items():\n",
    "    ws = wb.add_worksheet(f\"K - {LABEL_MAP[model]}\")\n",
    "    row = 0\n",
    "    col = 0\n",
    "    ws.merge_range(row, col, row, col+5, f\"Clustered Sample Size Estimates by Z-Threshold, Mean N/K, ICC and 95% CI Half-Width [{LABEL_MAP[model]}]\", formats[\"heading\"])\n",
    "    row += 1\n",
    "    df.write_excel(\n",
    "        wb, ws, position=(row, col),\n",
    "        table_style=\"Table Style Medium 9\",\n",
    "        autofit=True,\n",
    "        column_formats={\n",
    "            \"Z-Threshold\": {\"bold\": True},\n",
    "            \"Sensitivity\": {\"bold\": True},\n",
    "            \"Specificity\": {\"bold\": True},\n",
    "        },\n",
    "        conditional_formats={\n",
    "            (\"Sensitivity\", \"Specificity\"): {\n",
    "                \"type\": \"3_color_scale\"\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    ws.set_column(0, 0, 15)\n",
    "    ws.freeze_panes(2, 0)\n",
    "wb.close()"
   ],
   "id": "5116764c0b61fe7e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
