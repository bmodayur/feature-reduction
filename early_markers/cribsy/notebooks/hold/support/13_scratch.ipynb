{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "doc-main-summary",
   "metadata": {},
   "source": [
    "# 13 - Scratchpad and Experimental Code\n",
    "\n",
    "**Purpose**: This notebook serves as a development scratchpad for testing new ideas, running one-off analyses, and prototyping code before it is integrated into the main analysis workflows. The cells below may not represent a coherent, linear workflow and often contain fragmented or experimental code.\n",
    "\n",
    "**Inputs**: Varies by cell, but often uses data loaded via `get_dataframes()` or `BayesianData`.\n",
    "\n",
    "**Outputs**: Primarily in-line console output and visualizations for quick, interactive analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "doc-cell-1",
   "metadata": {},
   "source": [
    "### 13.1 PCA for Dimensionality Reduction\n",
    "\n",
    "This cell explores using Principal Component Analysis (PCA) to reduce the dimensionality of the feature set...\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import polars as pl\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from early_markers.cribsy.common.hold.data import get_dataframes\n",
    "\n",
    "\n",
    "data = get_dataframes()\n",
    "\n",
    "# PCA to reduce dimensionality\n",
    "df = data[\"train\"].with_columns(\n",
    "    feature=pl.col(\"part\") + \"_\" + pl.col(\"feature_name\")\n",
    ")\n",
    "df_38 = data[\"features_38\"]\n",
    "\n",
    "df_train = df.join(\n",
    "    df_38.with_columns(\n",
    "        feature = pl.col(\"part\") + \"_\" + pl.col(\"feature_name\")\n",
    "    ).select(\"feature\"),\n",
    "    on=\"feature\",\n",
    "    how=\"inner\"\n",
    ").pivot(\n",
    "    on=\"feature\",\n",
    "    index=\"infant\",\n",
    "    values=\"Value\",\n",
    ")\n",
    "\n",
    "pca = PCA(n_components=9)\n",
    "ref_pca = pca.fit_transform(df_train.drop(\"infant\"))"
   ],
   "id": "23c2732322e90851",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Plan\n",
    "- Get means and sds of features\n",
    "- Calculate min/max N by number of classes\n",
    "-"
   ],
   "id": "4b8230100cbb6107"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pca.explained_variance_ratio_",
   "id": "7bf646967a48c0a8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "# Split dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply PCA to reduce dimensionality\n",
    "pca = PCA(n_components=2)  # Reduce to 2 dimensions\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# Train Naive Bayes classifier on reduced data\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train_pca, y_train)\n",
    "\n",
    "# Evaluate model performance\n",
    "accuracy = gnb.score(X_test_pca, y_test)\n",
    "print(f\"Accuracy after PCA: {accuracy}\")\n",
    "\n",
    "\n"
   ],
   "id": "7903348a5e0fafe1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "\n"
   ],
   "id": "c09e040680f4ef09",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "SIZES = (50, 100)\n",
    "PROBS = (0.008, 0.99)\n",
    "\n",
    "def linear_interpolation(a, a0, a1, b0, b1):\n",
    "    \"\"\"\n",
    "    Linearly interpolate to map a value from range A to range B.\n",
    "\n",
    "    Parameters:\n",
    "    a: The value to interpolate\n",
    "    a0, a1: The min and max values of range A\n",
    "    b0, b1: The min and max values of range B\n",
    "\n",
    "    Returns:\n",
    "    The interpolated value in range B\n",
    "    \"\"\"\n",
    "    if a0 == a1:  # Handle division by zero case\n",
    "        return (b0 + b1) / 2\n",
    "\n",
    "    # Apply the linear interpolation formula\n",
    "    return b0 + (a - a0) * (b1 - b0) / (a1 - a0)\n",
    "\n",
    "# linear_interpolation(75, 50, 100, 0.0, 0.99)\n",
    "linear_interpolation(0.95, 0.0, 0.99, 50, 100)"
   ],
   "id": "d5928e326c982b1d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def numpy_interpolation(a, range_a, range_b):\n",
    "    if range_a[0] == range_a[1]:  # Handle division by zero case\n",
    "        return (range_b[0] + range_b[1]) / 2\n",
    "\n",
    "    return np.interp(a, range_a, range_b)\n",
    "\n",
    "numpy_interpolation(0.95, (0.0, 0.99), (50, 100))"
   ],
   "id": "f4b96ba6355c3b1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from statistics import mean\n",
    "\n",
    "mean([0.929, 0.857, 0.714, 0.857, 0.857, 0.786, 0.786,])\n",
    "# sens 0.8265714285714286\n",
    "# spec 0.6857142857142857\n",
    "mean([0.625, 0.675, 0.775, 0.650, 0.600, 0.775, 0.700,])"
   ],
   "id": "f4242a1542b52443",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
